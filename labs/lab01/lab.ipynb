{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 ‚Äì Introduction\n",
    "\n",
    "## DSC 80, Fall 2023\n",
    "\n",
    "### Due Date: Monday, October 9th at 11:59PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Welcome to the first assignment in DSC 80 this quarter!\n",
    "\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and Markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding will be done in an accompanying `lab.py` file that is imported into the current notebook, and **you will only submit that `lab.py` file**, not this notebook!\n",
    "\n",
    "Some additional guidelines:\n",
    "- **Unlike in DSC 10, labs will have both public tests and hidden tests.** The bulk of your grade will come from your scores on hidden tests, which you will only see on Gradescope after the assignment deadline.\n",
    "- **Do not change the function names in the `lab.py` file!** The functions in the `lab.py` file are how your assignment is graded, and they are graded by their name. If you changed something you weren't supposed to, you can find the original code in the [course GitHub repository](https://github.com/dsc-courses/dsc80-2023-fa).\n",
    "- Notebooks are nice for testing and experimenting with different implementations before designing your function in your `lab.py` file. You can write code here, but make sure that all of your real work is in the `lab.py` file, since that's all you're submitting.\n",
    "- **To ensure that all of your work to be submitted is in `lab.py`, we've provided an additional uneditable notebook, called `lab-validation.ipynb`, that contains only the tests and their setup. Make sure you are able to run it top-to-bottom without error before submitting!**\n",
    "- You are encouraged to write your own additional helper functions to solve the lab, as long as they also end up in `lab.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing code from `lab.py`**:\n",
    "\n",
    "* Below, we import the `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infrastructure Summary\n",
    "\n",
    "Run the following cell to see a [YouTube video üé•](https://youtu.be/PPKXJqu2XmY) that summarizes the above information and walks you through how to\n",
    "- set up your programming environment (see the instructions in [Tech Support](https://dsc80.com/tech_support) for more details),\n",
    "- access assignments,\n",
    "- work on and test assignments, and\n",
    "- submit assignments.\n",
    "\n",
    "The video is also linked on the [Resources tab of the course website](https://dsc80.com/resources).\n",
    "\n",
    "<span style=\"color:red\"> **Note:**</span> The instruction video is cloning from the repository `dsc80-2023-wi`, but you need to clone from `dsc80-2023-fa`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('PPKXJqu2XmY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started! üéâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Python Basics üêç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 0 ‚Äì Consecutive Integers\n",
    "\n",
    "Complete the implementation of the function `consecutive_ints`, which takes in a possibly empty list of integers (`ints`) and returns `True` if there exist two adjacent list elements that are consecutive integers and `False` otherwise.\n",
    "\n",
    "For example, since `9` is next to `8`, `consecutive_ints([5, 3, 6, 4, 9, 8])` should evaluate to `True`, since `9` and `8` are consecutive integers. On the other hand, `consecutive_ints([1, 3, 5, 7, 9])` should evaluate to `False`.\n",
    "\n",
    "***Note***: If you look at `lab.py`, you'll notice that the solution to this problem is already there. This question is done for you to show you what a completed homework problem looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The cells below are here for you to write scratch work in. \n",
    "# You should write the code for your answer in `lab.py`, not here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the public tests on your code for a given question, run the cell containing a call to `grader.check` that immediately follows it. \n",
    "\n",
    "Remember, your grade will primarily be determined by hidden tests, which are **not** run when you run `grader.check`, so it's important to extensively test your functions on your own by calling them on different inputs. Does they work for edge cases? Real-world data is **very messy** and you should expect your data processing code to break without thorough testing!\n",
    "\n",
    "You can write custom tests either by calling your functions on different inputs here in the notebook, or by writing doctests in `lab.py`, as you did in DSC 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 ‚Äì Median vs. Mean\n",
    "\n",
    "Complete the implementation of the function `median_vs_mean`, which takes in a non-empty list of numbers (`nums`) and returns `True` if median of the list is less than or equal to the mean of the list and `False` otherwise.\n",
    "\n",
    "Recall, if a list has even length, the median is the mean of the middle two elements.\n",
    "\n",
    "***Note:*** In this question, you may only use built-in functions and methods in Python. You should not use `numpy` or `pandas` at all, nor should you import any additional packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 ‚Äì Same Difference\n",
    "\n",
    "Complete the implementation of the function `same_diff_ints`, which takes in a list of integers (`ints`) and returns `True` if there exist two list elements $i$ positions apart, whose absolute difference as integers is also $i$. If there are no two elements satisfying this condition, `same_diff_ints` should return `False`.\n",
    "\n",
    "For example, because `3` (position 1) `5` (position 3) are 2 positions apart, and $|3-5| = 2$:\n",
    "```py\n",
    ">>> same_diff_ints([5, 3, 1, 5, 9, 8])\n",
    "True\n",
    "```\n",
    "Whereas:\n",
    "```py\n",
    ">>> same_diff_ints([1, 3, 5, 7, 9])\n",
    "False\n",
    "```\n",
    "\n",
    "**Important:** While implementing `same_diff_ints`, we will assume that `ints` tends to satisfy the condition, and that the pair(s) saitifying the condition tend to be close together. As such, you must implement `same_diff_ints` such that it **runs quicker in cases where the pairs are close together than in cases where the pairs are further apart**. While you will still likely need a nested `for`-loop, this will inform how you configure your loop variables. (Optimizing your code for an assumed distribution of incoming data is very common in data science).\n",
    "\n",
    "***Hint 1:*** This is similar to Question 0.\n",
    "\n",
    "***Hint 2:*** Make sure to define some extreme test cases, like when `ints` is an empty list. Also, use the `%%time` magic command to time your function, to make sure it satisfies the optimization requirement above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure your function runs in under 5 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "same_diff_ints([5, 3, 1, 5, 9, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Strings and Files üßµ\n",
    "\n",
    "The following questions will familiarize you with the basics of working with strings and reading data from files. Remember that by default, data from files are stored as strings in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 ‚Äì $n$ Prefixes\n",
    "\n",
    "Complete the implementation of the function `n_prefixes`, which takes a string `s` and a positive integer `n`. It returns a string containing the first `n` consecutive prefixes of `s` in reverse order.\n",
    "\n",
    "For example, let's suppose `s` is the string `'Billy!'` and `n` is `4`. The consecutive prefixes of `'Billy!'` are:\n",
    "- `'B'`\n",
    "- `'Bi'`\n",
    "- `'Bil'`\n",
    "- `'Bill'`\n",
    "- `'Billy'`\n",
    "- `'Billy!'`\n",
    "\n",
    "The first 4 of these are `'B'`, `'Bi'`, `'Bil'`, and `'Bill'`. If we combine these 4 in reverse order, we get `'BillBilBiB'`, which is what `n_prefixes('Billy!', 4)` should return. As another example, `n_prefixes('Marina', 3)` should return `'MarMaM'`. **You may assume that `n` is no larger than the length of `s`.**\n",
    "\n",
    "***Hint:*** Recall that [strings may be sliced](https://docs.python.org/3/tutorial/introduction.html#strings), like lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 ‚Äì Exploded Numbers üí£\n",
    "\n",
    "Complete the implementation of the function `exploded_numbers`, which takes in a list of integers (`ints`) and a non-negative integer (`n`) and **returns a list of strings** containing numbers from the list expanded by `n` numbers in both directions, separated by spaces. Each integer should be [zero padded](https://www.tutorialspoint.com/python/string_zfill.htm) so that all integers outputted have the same length.\n",
    "\n",
    "For example, consider `exploded_numbers([3, 8, 15], 2)`.\n",
    "- If we explode 3 by 2 numbers in both directions, we get 1, 2, 3, 4, 5.\n",
    "- If we explode 8 by 2 numbers in both directions, we get 6, 7, 8, 9, 10.\n",
    "- If we explode 15 by 2 numbers in both directions, we get 13, 14, 15, 16, 17.\n",
    "\n",
    "The longest length of any of the exploded numbers above is 2, so all of the outputted integers should have length 2.\n",
    "\n",
    "- The string corresponding to 3 in the input is `'01 02 03 04 05'`.\n",
    "- The string corresponding to 8 in the input is `'06 07 08 09 10'`.\n",
    "- The string corresponding to 15 in the input is `'13 14 15 16 17'`.\n",
    "\n",
    "So, `exploded_numbers([3, 8, 15], 2)` should return `['01 02 03 04 05', '06 07 08 09 10', '13 14 15 16 17']`. \n",
    "\n",
    "As another example, `exploded_numbers([9, 99], 3)` should return `['006 007 008 009 010 011 012', '096 097 098 099 100 101 102']`.\n",
    "\n",
    "***Note***: You can assume that negative numbers will never be encountered. That is, when testing your code, we will never explode a number so much that it becomes negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 ‚Äì Reading Files\n",
    "\n",
    "[Recall](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files) that the built-in function `open` takes in a file path and returns *a file object* (sometimes called a *file handle*). Below are a few properties of file objects:\n",
    "\n",
    "* `open(path)` opens the file at location `path` for reading.\n",
    "* `open(path)` is an *iterable*, which contains successive lines of the file.\n",
    "* Once a file object is opened, after use it should be closed to avoid memory leaks. To ensure a file is closed once done, you should use a *context manager* as follows:\n",
    "```py\n",
    "with open(path) as fh:\n",
    "    for line in fh:\n",
    "        process_line(line)\n",
    "```\n",
    "* To read the entire file into a string, use the `read` method:\n",
    "```py\n",
    "with open(path) as fh:\n",
    "    s = fh.read()\n",
    "```\n",
    "\n",
    "However, you should be careful when reading an entire file into memory that the file isn't too big! *You should avoid this whenever possible!*\n",
    "\n",
    "Complete the implementation of the function `last_chars`, which takes in file object (`fh`) and returns a string consisting of the last character of each line. Note that you don't have to use `open` at all; the argument given to you is a file object, not a file path.\n",
    "\n",
    "***Note:*** A newline (`'\\n'`) is the \"delimiter\" of the lines of a file, and doesn't count as part of the line (as the tests imply). Every other character is part of the line. For more info on this, see [the interpretation](https://en.wikipedia.org/wiki/Newline#Interpretation) of files as a 'newline delimited variables' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct, you should see `'hrg'` when running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'chars.txt')\n",
    "last_chars(open(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: `numpy` exercises ü•ß\n",
    "\n",
    "For a refresher on `numpy` and arrays, refer to the relevant section of the [DSC 10 course notes](https://notes.dsc10.com/02-data_sets/arrays.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 ‚Äì Array Methods\n",
    "\n",
    "Complete the implementations of the functions `add_root` and `where_square`. Specifications are given below. Your solutions should **not** contain any loops or list comprehensions.\n",
    "\n",
    "#### `add_root`\n",
    "\n",
    "`add_root` should take in a `numpy` array, `A`, and return a new `numpy` array that contains the element-wise sum of the elements in `A` with the _square roots of the positions of the elements in `A`_. \n",
    "\n",
    "For instance, if `A` contains the values 5, 9, and 4, the output array should contain the values 5 (5 + $\\sqrt{0}$), 10 (9 + $\\sqrt{1}$), and 5.4142... (4 + $\\sqrt{2}$).\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `where_square`\n",
    "\n",
    "`where_square` should take in a `numpy` array, `A`, and return a new `numpy` array of Booleans whose `i`th element is `True` if and only if the `i`th element of `A` is a perfect square. \n",
    "\n",
    "For instance, `where_square(np.array([2, 9, 16, 15]))` should return `array([False, True, True, False])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell -- it is needed for the tests to work\n",
    "A_1 = np.array([2, 4, 6, 7])\n",
    "out_1 = add_root(A_1)\n",
    "\n",
    "A_2 = np.array([1, 2, 16, 17, 32, 49])\n",
    "out_2 = where_square(A_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 ‚Äì Stock Prices üìà\n",
    "\n",
    "Complete the implementations of the functions `growth_rates` and `with_leftover`. Specifications are given below. Your solutions should **not** contain any loops or list comprehensions.\n",
    "\n",
    "#### `growth_rates`\n",
    "\n",
    "`growth_rates` should take in a `numpy` array, `A`, of [stock prices](https://en.wikipedia.org/wiki/Stock) for a single stock on successive days in USD. It should return an array of growth rates. That is, the `i`th number of the returned array should contain the rate of growth in stock price between the $i^{th}$ day to the $(i+1)^{th}$ day. The growth rate between two values is defined as $\\frac{\\text{final} - \\text{initial}}{\\text{initial}}$. You should return growth rates as **proportions, rounded to two decimal places**.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `with_leftover`\n",
    "\n",
    "Again, suppose `A` is a `numpy` array of stock prices. Consider the following scheme: \n",
    "\n",
    "- Suppose that you start each day with \\$20 to purchase stocks. \n",
    "- Each day, you purchase as many shares as possible of the stock. (The price changes each day, according to `A`.)\n",
    "- Any money left-over after a given day is saved for possibly buying stock on a future day.\n",
    "\n",
    "The function `with_leftover` should take in `A` and return the day (as an `int`) on which you can buy at least one full share using just \"left-over\" money. If this never happens, return `-1`. Note that the first stock purchase occurs on Day 0, and that you cannot purchase fractions of a share of a stock.\n",
    "\n",
    "For example, if the stock price is \\$3 every day, then the answer is `1` (corresponding to Day 1):\n",
    "- Day 0: Buy 6 stocks with \\\\$20, and \\\\$2 is added to the leftover. Your total leftover is currently \\\\$2. This is not enough to buy one extra share, so you continue.\n",
    "- Day 1: Buy 6 stocks with \\\\$20, and another \\\\$2 is added to the leftover. Your total leftover is now \\\\$4, so you can now buy one extra share. Hence, the answer is Day 1, and `with_leftover` should return `1`.\n",
    "\n",
    "***Hint:*** `np.cumsum` may be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell -- it is needed for the tests to work\n",
    "fp = os.path.join('data', 'stocks.csv')\n",
    "stocks = np.array([float(x) for x in open(fp)])\n",
    "out_3_stocks = growth_rates(stocks)\n",
    "\n",
    "A_4 = np.array([3, 3, 3, 3])\n",
    "out_4 = with_leftover(A_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Introduction to `pandas` üêº\n",
    "\n",
    "This part will help build familiarity with DataFrames in `pandas`. Fortunately, you've already a version of `pandas` before in DSC 10, called `babypandas`! Review the [DSC 10 course notes](https://notes.dsc10.com/02-data_sets/dataframes.html) as necessary.\n",
    "\n",
    "One key difference between `babypandas` and `pandas` is the idiomatic way of accessing a column. In `babypandas`, to access column `'x'` in DataFrame `df`, you used `df.get('x')`. In `pandas`, the more common way is `df['x']`.\n",
    "\n",
    "As always for `pandas` questions:\n",
    "1. Avoid writing loops through the rows of the DataFrame to do the problem, and\n",
    "2. Test the output/correctness of your code with the help of the dataset given, but be sure your code will also run on data that is similar to but different from the dataset given. (One way to do this is to sample rows from the provided DataFrame using the `.sample` method)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `data/salary.csv` contains salary information for the 2021-22 National Basketball Association (NBA) season üèÄ. Specifically, it contains the name, team, and salary of all players who have played at least 15 games last season. We will load this file and store it as a DataFrame named `salary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not edit this cell -- it is needed for the tests\n",
    "salary_fp = os.path.join('data', 'salary.csv')\n",
    "salary = pd.read_csv(salary_fp)\n",
    "salary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8 ‚Äì `pandas` Basics\n",
    "\n",
    "Your job is to complete the implementation of the function `salary_stats`, which takes in a DataFrame like `salary` and returns a **Series** containing the following statistics:\n",
    "- `'num_players'`: The number of players.\n",
    "- `'num_teams'`: The number of teams.\n",
    "- `'total_salary'`: The total salary amount for all players.\n",
    "- `'highest_salary'`: The name of the player with the highest salary. **Assume there are no ties.**\n",
    "- `'avg_los'`: The average salary of the `'Los Angeles Lakers'`, rounded to two decimal places.\n",
    "- `'fifth_lowest'`: The name and team of the player who has the fifth lowest salary, separated by a comma and a space (e.g. `'Billy Triton, Cleveland Cavaliers'`). **Assume there are no ties.**\n",
    "- `'duplicates'`: A Boolean that is `True` if there are any duplicate last names, and `False` otherwise. Note that some players may have a suffix on their name, such as \"Jr.\" or \"III\" -- you should ignore these. That is, \"Billy Triton Jr.\" and \"Tyler Triton\" should be considered to have the same last name.\n",
    "- `'total_highest'`: The total salary of the team that has the highest paid player.\n",
    "\n",
    "The index of each element in the outputted Series is specified above.\n",
    "\n",
    "***Note 1***: Your function should work on a dataset of the same format that contains information from other years. This means that `salary_stats` should not \"hard-code\" any numbers or strings, but should compute them all programatically. In all cases, you may assume that none of the answers involving ranking involves a tie.\n",
    "\n",
    "***Note 2***: The doctests and public tests don't test to see if your function returns the right numbers. You should manually inspect your result to make sure that all values seem appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do not edit this cell -- it is needed for the tests\n",
    "salary_fp = os.path.join('data', 'salary.csv')\n",
    "salary = pd.read_csv(salary_fp)\n",
    "stats = salary_stats(salary)\n",
    "\n",
    "salary_sample = pd.read_csv('data/salary_sample.csv')\n",
    "sample_stats = salary_stats(salary_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9 ‚Äì Reading Malformed `.csv` Files\n",
    "\n",
    "`data/malformed.csv` is a file of comma-separated values, containing the following fields:\n",
    "\n",
    "\n",
    "|column name|description|type|\n",
    "|---|---|---|\n",
    "|`'first'`|first name of person|`str`|\n",
    "|`'last'`|last name of person|`str`|\n",
    "|`'weight'`|weight of person (lbs)|`float`|\n",
    "|`'height'`|height of person (in)|`float`|\n",
    "|`'geo'`|location of person; comma-separated latitude/longitude|`str`|\n",
    "\n",
    "Unfortunately, the entries contains errors that cause `pandas`' `read_csv` function to fail parsing the file with the default settings. Instead, you must read in the file manually using Python's built-in `open` function.\n",
    "\n",
    "Complete the implementation of the function `parse_malformed`, which takes in a file path (`fp`) and returns a parsed, properly-typed DataFrame. The DataFrame should contain columns as described in the table above (with the specified types); it should agree with `pd.read_csv` when the lines are not malformed.\n",
    "\n",
    "***Note:*** Assume that the given `.csv` file is a sample of a larger file; you will be graded against a **different** sample of the larger file that has the same type of parsing errors. That is, you should **not** hard-code your cleaning of the data to specific errors on specific lines in the data.\n",
    "\n",
    "***Hint:*** Open `data/malformed.csv` in your text editor, and look very carefully at the placement of commas (`,`) and quotes (`\"`). The first few rows of `parse_malformed('data/malformed.csv')` should be:\n",
    "\n",
    "<img src=\"./imgs/example-df.png\" width=45%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do not edit -- needed for tests\n",
    "fp = os.path.join('data', 'malformed.csv')\n",
    "cols = ['first', 'last', 'weight', 'height', 'geo']\n",
    "df = parse_malformed(fp)\n",
    "dg = pd.read_csv(fp, nrows=4, skiprows=10, names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done Lab 1! üèÅ\n",
    "\n",
    "As a reminder, all of the work you want to submit needs to be in `lab.py`.\n",
    "\n",
    "To verify that all of your work is indeed in `lab.py`, and that you didn't accidentally implement a function in this notebook and not in `lab.py`, we've included another notebook in the lab folder, called `lab-validation.ipynb`. `lab-validation.ipynb` is a version of this notebook with only the `grader.check` cells and the code needed to set up the tests. \n",
    "\n",
    "### **Go to `lab-validation.ipynb`, and go to Kernel > Restart & Run All.** This will check if all `grader.check` test cases pass using just the code in `lab.py`.\n",
    "\n",
    "Once you're able to pass all test cases in `lab-validation.ipynb`, including the call to `grader.check_all()` at the very bottom, then you're ready to submit your `lab.py` (and only your `lab.py`) to Gradescope. Once submitting to Gradescope, make sure to stick around until all test cases pass.\n",
    "\n",
    "There is also a call to `grader.check_all()` below in _this_ notebook, but make sure to also follow the steps above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "nteract": {
   "version": "0.15.0"
  },
  "otter": {
   "tests": {
    "q0": {
     "name": "q0",
     "points": 0,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> consecutive_ints([5, 3, 6, 4, 9, 8])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> consecutive_ints([1, 3, 5, 7, 9]) == False\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> consecutive_ints([]) == False\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> median_vs_mean([6, 5, 4, 3, 2])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> median_vs_mean([50, 20, 15, 40])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> median_vs_mean([1, 8, 9]) == False\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> same_diff_ints([5, 3, 1, 5, 9, 8])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> same_diff_ints([1, 3, 5, 7, 9]) == False\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> n_prefixes('Billy', 4) == 'BillBilBiB'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> n_prefixes('Marina', 3) == 'MarMaM'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> n_prefixes('aaron', 2) == 'aaa'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> n_prefixes('Justin', 5) == 'JustiJustJusJuJ'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> exploded_numbers([3, 8, 15], 2) == ['01 02 03 04 05', '06 07 08 09 10', '13 14 15 16 17']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> exploded_numbers([9, 99], 3) == ['006 007 008 009 010 011 012', '096 097 098 099 100 101 102']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> fp = os.path.join('data', 'chars.txt')\n>>> last_chars(open(fp)) == 'hrg'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(out_1, np.ndarray)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.all(out_1 >= A_1)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(out_1[3], 7 + np.sqrt(3))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(out_2, np.ndarray)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_2.dtype == np.dtype('bool')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_2[2]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out_3_stocks.dtype == np.dtype('float')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_3_stocks.max() == 0.03\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> import numbers\n>>> isinstance(out_4, numbers.Integral)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_4 == 1\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(stats, pd.Series)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 'total_highest' in stats.index\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(stats.loc['duplicates'], bool) or isinstance(stats.loc['duplicates'], np.bool_)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9": {
     "name": "q9",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> list(df.columns) == cols\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> df['last'].dtype == np.dtype('O')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> df['height'].dtype == np.dtype('float64')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> df['geo'].str.contains(',').all()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(df) == 100\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> dg.index = range(9, 13)\n>>> (dg == df.iloc[9:13]).all().all()\nTrue",
         "failure_message": "doctest examples",
         "hidden": false,
         "locked": false,
         "points": 6
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
