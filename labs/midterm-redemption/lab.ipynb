{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e3c18a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd810569",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Midterm Redemption\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c27d69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Question 0\n",
    "\n",
    "The exam redemption consists of 8 questions worth a total of 25 points. Please complete the exam redemption. Here are a few things that differ from the midterm:\n",
    "\n",
    "To make things work on Gradescope, instead of assigning variables directly using the correct code, you should fill in functions in `lab.py`, just like you would for a normal lab. Each function takes no arguments but should return the value you would normally assign to the variable. Hereâ€™s an example:\n",
    "\n",
    "In the exam, you wrote:\n",
    "```python\n",
    "answer = 1 + 1\n",
    "```\n",
    "\n",
    "But in the redemption, you will write:\n",
    "\n",
    "```python\n",
    "def answer_function():\n",
    "    return 1 + 1\n",
    "```\n",
    "\n",
    "Please refer to the lab.py file to see the names of the functions corresponding to each question.\n",
    "\n",
    "Feel free to post any logistical questions about this redemption on Ed, but note that course staff will not answer questions related to how to debug or solve the problems.\n",
    "\n",
    "Start by running the cell below to import the packages needed for the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "15d302fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e96fb114",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "17c4a086",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from dsc80_utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecdd7b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Parks!\n",
    "Sam is working with a dataset on visits to US National Parks. There are two CSV files that he's working with: `data/parks.csv` and `data/visits.csv`. The columns of each dataset are described below.\n",
    "\n",
    "`data/parks.csv`:\n",
    "\n",
    "- `park_id` (`int`): A unique identifier for a park.\n",
    "- `parkname` (`str`): The name of each park. `NP` is short for National Park. `PRES` is short for Preserve.\n",
    "- `region` (`str`): The region of the US that the park is in. \n",
    "- `state` (`str`): The two-letter abbreviation for the state that the park is in.\n",
    "\n",
    "`data/visits.csv`:\n",
    "\n",
    "- `name` (`str`): The full name of the park visitor. You can assume that no two people share the same first and list name.\n",
    "- `entry` (`datetime64`): The timestamp that the visitor entered the park.\n",
    "- `duration` (`int`): The number of hours that each person stayed at the park.\n",
    "- `park_id` (`int`): The park ID that the person stayed at.\n",
    "\n",
    "Run the cell below to load the two CSV files into two Pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ce077639",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parks = pd.read_csv('data/parks.csv')\n",
    "visits = pd.read_csv('data/visits.csv', parse_dates=['entry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9aa7ebf3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parks.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "33f4ccd5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visits.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d4ae34",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now, run the cell below to define two more dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d3c7803c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = parks.merge(visits, on='park_id', how='inner')\n",
    "df2 = parks.merge(visits, on='park_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a634913",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Write Python code below to compute each of the following desired results using the dataframes `parks`, `visits`, `df1`, and `df2`. Unless otherwise stated, all number and boolean results should be numpy types (e.g. `np.float64` instead of `float`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92801ba1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Question 1 \n",
    "**(3 points)**\n",
    "Fill in `amina_function` so that it\n",
    "returns the number of times that Amina Garcia visited a national park as \n",
    "an `int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80368fbf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6681a710",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a06bea",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd792dbf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Question 2\n",
    "**(4 points)**\n",
    "Fill in `least_function` so that it\n",
    "returns the year with the least number of park visits in this dataset.\n",
    "Your function should return an `int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1764341",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6bda75",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894cecbc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d60ae",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Question 3 \n",
    "**(5 points)**\n",
    "Fill in `never_function` so that it\n",
    "returns the names of all national parks that were **never** visited by someone in this dataset.\n",
    "Your function should return a `numpy` array of strings.\n",
    "(If all national parks were visited, `never_function` should return an empty numpy array.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc082346",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d8e91d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1382ced",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Dog-gone data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a1fd5f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Sam was analyzing the parks data when his dog Bentley ate his data (again!).\n",
    "Sam's table is stored in a dataframe called `df` that is now missing some values in the `duration` column.\n",
    "Your task is to impute the missing duration values as effectively as possible, such that the mean and the variance of the `duration` column after imputation is as close as possible to the original data.\n",
    "First, start by running the cell below to load in Sam's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2adf424e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/visits_missing_a.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bc3ccd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Question 4\n",
    "**(1 point)**\n",
    "Fill in `prop_missing_function` so that it\n",
    "returns the proportion of values that are missing in the `duration` column.\n",
    "Your function should return a number between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699cb735",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64601b9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c6145",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Question 5 \n",
    "**(2 points)**\n",
    "We've imported the following functions from `dsc80_utils.py`. \n",
    "\n",
    "- `permutation_test(data, col, group_col, test_statistic, N)`\n",
    "- `diff_in_means(data, col, group_col)`\n",
    "- `tvd(data, col, group_col)`\n",
    "- `ks(data, col, group_col)`\n",
    "\n",
    "As usual, you can view the complete docstrings for these functions by adding a `?` after the function name, for example, by running:\n",
    "\n",
    "```python\n",
    "permutation_test?\n",
    "```\n",
    "\n",
    "Now, run the following cell, which runs a permutation test for the following hypotheses:\n",
    "\n",
    "- Null: The distribution of `entry_hour` is the same for park entries in 2020 and the rest of the years.\n",
    "- Alternative: The distribution of `entry_hour` is different for park entries in 2020.\n",
    "\n",
    "\n",
    "Using the results from `permutation_test`, compute the p-value for this hypothesis test and return it in `p_val_function()`. Then, fill in `reject_function()`, which returns `True` if you reject the null hypothesis or `False` if you fail to reject the null at the 0.01 significance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a73108",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3752bcb5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7637b8a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a0676d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Question 6\n",
    "**(3 points)** Run a permutation test to determine whether the missingness of `duration` is missing at random (MAR) dependent on `entry_hour`. \n",
    "\n",
    "Fill in `hour_pval_function()` so that it returns the p-value for your hypothesis test. Then, fill in `hour_mar_function()` with your conclusion: `True` if `duration` is MAR dependent on `entry_hour` and `False` if not. Use a 0.01 significance level for your hypothesis tests.\n",
    "Be sure to choose the appropriate test statistic for this hypothesis test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff8cd18",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40443b3d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84388458",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11788d47",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Question 7\n",
    "**(4 points)** Now, run a permutation test to determine whether the missingness of `duration` is missing at random (MAR) dependent on **any other column** in `df`: `region`, `entry_year`, and `entry_month`. Use a 0.01 significance level.\n",
    "\n",
    "For each permutation test, choose the appropriate test statistic, and return your p-values as a dictionary from the function `pvals_function()`. The returned dictionary should have one key for each column (`region`, `entry_year`, and `entry_month`). Each value in the dictionary should be the p-value for the hypothesis test to determine whether `duration` is MAR on that column.\n",
    "\n",
    "`pvals_function()` should return a dictionary with these keys (and different values):\n",
    "\n",
    "```python\n",
    "{\n",
    "    'region': 0.02,\n",
    "    'entry_year': 0.50,\n",
    "    'entry_month': 0.70\n",
    "}\n",
    "```\n",
    "\n",
    "Then, fill in `mar_cols_function` so that it returns a dictionary that marks all the columns that the `duration` column is MAR on (`True` if `duration` is MAR on that column and `False` if not).\n",
    "\n",
    "`mar_cols_function()` should return a dictionary with these keys (and different values):\n",
    "\n",
    "```python\n",
    "{\n",
    "    'region': True,\n",
    "    'entry_year': False,\n",
    "    'entry_month': True,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca32ca54",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeedfcd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b0c9b2d3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## don't delete this cell, but do run it -- it is needed for the autograder tests\n",
    "mar_cols = mar_cols_function()\n",
    "pval = pvals_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214cde38",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bde0c1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Question 8\n",
    "**(3 points)** Fill in `df_imputed_function()`, which should impute the missing `duration` values using probabilistic imputation, **conditional on the columns that `duration` is MAR on**.\n",
    "You should make use of the `prob_impute` function defined below (which is copied directly from lecture).\n",
    "\n",
    "`df_imputed_function()` should return a copy of `df` with one extra column called `imputed` containing the imputed duration values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fd82a2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9be4675",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "03502c4c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## don't delete this cell, but do run it -- it is needed for the autograder tests\n",
    "np.random.seed(42)\n",
    "df_imputed = df_imputed_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b48a71",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aeec10",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e7b96",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> amina = amina_function()\n>>> isinstance(amina, (int, np.integer))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(least_function(), (int, np.integer))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> #isinstance(least_function(), (int, np.integer))\n>>> bool(least_function() > 2000)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(never_function(), np.ndarray)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> all(isinstance(i, str) for i in never_function())\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(prop_missing_function(), (float, np.floating))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> bool(0 < prop_missing_function() < 1)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(p_val_function(), (float, np.floating))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> isinstance(reject_function(), bool)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(hour_pval_function(), (float, np.floating))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(hour_mar_function(), bool)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(pval, dict)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> set(pval.keys()) == {'region', 'entry_year', 'entry_month'}\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> all(isinstance(i, (float, np.floating)) for i in pval.values())\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> all(0 <= i <= 1 for i in pval.values())\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> isinstance(mar_cols, dict)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> set(mar_cols.keys()) == {'region', 'entry_year', 'entry_month'}\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> all(isinstance(i, (bool, np.bool_)) for i in mar_cols.values())\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(df_imputed, pd.DataFrame)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> set(df_imputed.columns) == {'region', 'duration', 'entry_year', 'entry_month', 'entry_hour', 'imputed'}\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> df_imputed.shape == (5000, 6)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
