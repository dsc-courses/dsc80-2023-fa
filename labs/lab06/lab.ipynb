{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b8b508",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f1bc76",
   "metadata": {},
   "source": [
    "# Lab 6 – APIs and Web Scraping\n",
    "\n",
    "## DSC 80, Fall 2023\n",
    "\n",
    "### Due Date: Monday, November 13th at 11:59 PM \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc1863f",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Welcome to the sixth lab assignment in DSC 80 this quarter!\n",
    "\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and Markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding will be done in an accompanying `lab.py` file that is imported into the current notebook, and **you will only submit that `lab.py` file**, not this notebook!\n",
    "\n",
    "Some additional guidelines:\n",
    "- **Unlike in DSC 10, labs will have both public tests and hidden tests.** The bulk of your grade will come from your scores on hidden tests, which you will only see on Gradescope after the assignment deadline.\n",
    "- **Do not change the function names in the `lab.py` file!** The functions in the `lab.py` file are how your assignment is graded, and they are graded by their name. If you changed something you weren't supposed to, you can find the original code in the [course GitHub repository](https://github.com/dsc-courses/dsc80-2023-fa).\n",
    "- Notebooks are nice for testing and experimenting with different implementations before designing your function in your `lab.py` file. You can write code here, but make sure that all of your real work is in the `lab.py` file, since that's all you're submitting.\n",
    "- **To ensure that all of your work to be submitted is in `lab.py`, we've provided an additional uneditable notebook, called `lab-validation.ipynb`, that contains only the tests and their setup. Make sure you are able to run it top-to-bottom without error before submitting!**\n",
    "- You are encouraged to write your own additional helper functions to solve the lab, as long as they also end up in `lab.py`.\n",
    "\n",
    "**Importing code from `lab.py`**:\n",
    "\n",
    "* Below, we import the `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab` merely import the existing compiled python.\n",
    "    \n",
    "***Note***: In addition to the usual imports below, we'll need the `lxml` package that isn't included in the standard `dsc80` conda environment we had you configure.\n",
    "\n",
    "Before running the cell below for the first time, run the following line in your Terminal after activating your `dsc80` conda environment, and then restart your kernel. If you've already installed `lxml`, you should be able to run this cell without error.\n",
    "\n",
    "```\n",
    "pip install lxml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38385ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec842384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import bs4\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd68a76",
   "metadata": {},
   "source": [
    "## Question 1 – Practice with HTML Tags 📎\n",
    "\n",
    "In Question 2, you'll spend plenty of time parsing HTML source code. But before you get your hands dirty trying to extract information from HTML written by other people, it is a good idea to write basic HTML code yourself. This exercise will help you better understand how the code in a `.html` file is structured.\n",
    "\n",
    "For this question, you'll create a very basic `.html` file, named `lab06_1.html`, that satisfies the following conditions:\n",
    "\n",
    "- It must have `<title>` and `<head>` tags.\n",
    "- It must also have `<body>` tags. Within the `<body>` tags, it must have:\n",
    "    - At least two headers.\n",
    "    * At least three images.\n",
    "        - At least one image must be a local file.\n",
    "        - At least one image must be linked to online source.\n",
    "        - At least one image has to have default text when it cannot be displayed.\n",
    "    * At least three references (hyperlinks) to different web pages.\n",
    "    * At least one table with two rows and two columns.\n",
    "    \n",
    "\n",
    "Make sure to save your file as `lab06_1.html`, and save it in the same directory as `lab.py`. **When submitting this homework to Gradescope, make sure to also upload `lab06_1.html` along with the local image that you embedded in your site.** You can upload multiple files to Gradescope at a time.\n",
    "   \n",
    "\n",
    "***Notes***:\n",
    "- You can write and view basic HTML with a Jupyter Notebook, using either a Markdown cell or by using the `IPython.display.HTML` function (which takes in a string of HTML and renders it).\n",
    "- If you write your HTML code within a Jupyter Notebook, you should later copy your code into a text editor and save it with the `.html` extension. You could also write your HTML in a text editor directly.\n",
    "- Be sure to open your final `.html` file in a browser and make sure it looks correct on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede325f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47cb771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39e1ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't delete this cell!\n",
    "question1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432f1a11",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1184c48",
   "metadata": {},
   "source": [
    "## Question 2 – Scraping an Online Bookstore 📚\n",
    "\n",
    "Browse through the following fake online bookstore: http://books.toscrape.com/. This website is meant for toying with scraping.\n",
    "\n",
    "Your job is to scrape the website, collecting data on all books that have:\n",
    "- **_at least_ a four-star rating**, and\n",
    "- **a price _strictly_ less than £50**, and \n",
    "- **belong to specific categories** (more details below). \n",
    "\n",
    "You will extract the information into a DataFrame that looks like the one below.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>UPC</th>\n",
    "      <th>Product Type</th>\n",
    "      <th>Price (excl. tax)</th>\n",
    "      <th>Price (incl. tax)</th>\n",
    "      <th>Tax</th>\n",
    "      <th>Availability</th>\n",
    "      <th>Number of reviews</th>\n",
    "      <th>Category</th>\n",
    "      <th>Rating</th>\n",
    "      <th>Description</th>\n",
    "      <th>Title</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>e10e1e165dc8be4a</td>\n",
    "      <td>Books</td>\n",
    "      <td>Â£22.60</td>\n",
    "      <td>Â£22.60</td>\n",
    "      <td>Â£0.00</td>\n",
    "      <td>In stock (19 available)</td>\n",
    "      <td>0</td>\n",
    "      <td>Default</td>\n",
    "      <td>Four</td>\n",
    "      <td>For readers of Laura Hillenbrand's Seabiscuit...</td>\n",
    "      <td>The Boys in the Boat: Nine Americans...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>c2e46a2ee3b4a322</td>\n",
    "      <td>Books</td>\n",
    "      <td>Â£25.27</td>\n",
    "      <td>Â£25.27</td>\n",
    "      <td>Â£0.00</td>\n",
    "      <td>In stock (19 available)</td>\n",
    "      <td>0</td>\n",
    "      <td>Romance</td>\n",
    "      <td>Five</td>\n",
    "      <td>A Michelin two-star chef at twenty-eight, Violette...</td>\n",
    "      <td>Chase Me (Paris Nights #2)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>00bfed9e18bb36f3</td>\n",
    "      <td>Books</td>\n",
    "      <td>Â£34.53</td>\n",
    "      <td>Â£34.53</td>\n",
    "      <td>Â£0.00</td>\n",
    "      <td>In stock (19 available)</td>\n",
    "      <td>0</td>\n",
    "      <td>Romance</td>\n",
    "      <td>Five</td>\n",
    "      <td>No matter how busy he keeps himself...</td>\n",
    "      <td>Black Dust</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "To do so, implement the following functions.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `extract_book_links`\n",
    "\n",
    "Complete the implementation of the function `extract_book_links`, which takes in the content of a page that contains book listings as a **string of HTML**, and returns a **list** of URLs of book-specific pages for all books with **_at least_ a four-star rating and a price _strictly_ less than £50**. \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `get_product_info`\n",
    "\n",
    "Complete the implementation of the function `get_product_info`, which takes in the content of a book-specific page as a **string of HTML**, and a list `categories` of book categories. If the input book is in the list of `categories`, `get_product_info` should return a dictionary corresponding to a row in the DataFrame in the image above (where the keys are the column names and the values are the row values). If the input book is not in the list of `categories`, return `None`.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `scrape_books`\n",
    "\n",
    "Finally, put everything together. Complete the implementation of the function `scrape_books`, which takes in an integer `k` and a list `categories` of book categories. `scrape_books` should use `requests` to scrape the first `k` pages of the bookstore and return a DataFrame of only the books that have \n",
    "- **_at least_ a four-star rating**, and\n",
    "- **a price _strictly_ less than £50**, and\n",
    "- **a category that is in the list `categories`**.\n",
    "\n",
    "<br>\n",
    "\n",
    "Some general guidance and tips:\n",
    "\n",
    "- The first page of the bookstore is at http://books.toscrape.com/catalogue/page-1.html. Subsequent pages can be found by clicking the \"Next\" button at the bottom of the page. Look at how the URLs change each time you navigate to a new page; think about how to use f-strings (or some other string formatting technique) to generate these URLs.\n",
    "- Use \"inspect element\" to view the source code of the pages you're trying to scrape. To find a book's category, look at the hyperlinks in the book-specific page for that book.\n",
    "- **`scrape_books` should run in under 180 seconds on the entire bookstore (`k = 50`). `scrape_books` is also the only function that should make `GET` requests; the other two functions parse already-existing HTML.**\n",
    "- When instantiating `bs4.BeautifulSoup` objects, use the optional argument `features='lxml'` to suppress any warnings.\n",
    "- Don't worry about typecasting, i.e. it's fine if `'Number of reviews'` is not stored as type `int`. Also, don't worry if you run into encoding errors in your price columns (as the example DataFrame at the top of this cell contains)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e9281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0678f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f779c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't delete this cell, but do run it -- it is needed for the autograder tests\n",
    "\n",
    "# public test for extract_book_links \n",
    "extract_book_links_fp = os.path.join('data', 'products.html')\n",
    "extract_book_out = extract_book_links(\n",
    "    open(extract_book_links_fp, encoding='utf-8').read()\n",
    ")\n",
    "extract_book_url = 'scarlet-the-lunar-chronicles-2_218/index.html'\n",
    "\n",
    "# doc tests for get product info\n",
    "get_product_info_fp = os.path.join('data', 'Frankenstein.html')\n",
    "get_product_info_out = get_product_info(\n",
    "    open(get_product_info_fp, encoding='utf-8').read(), ['Default']\n",
    ")\n",
    "\n",
    "# public test for scrape books \n",
    "scrape_books_out = scrape_books(1, ['Mystery'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e171a2a0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321305c0",
   "metadata": {},
   "source": [
    "## Question 3 – API Requests 🤑\n",
    "\n",
    "You trade stocks as a hobby. As an avid `pandas` coder, you decide to calculate statistics of your favorite stocks by pulling data from a public API. The API we will work with can be found at https://financialmodelingprep.com/developer/docs/#Stock-Historical-Price. Specifically, we will use the \"**Historical Daily Prices with change and volume interval**\" endpoint (search for it at the linked page).\n",
    "\n",
    "Some relevant definitions:\n",
    "- Ticker: A short code that refers to a stock. For example, Apple's ticker is AAPL and Ford's ticker is F. \n",
    "- Open: The price of a stock at the beginning of a trading day.\n",
    "- Close: The price of a stock at the end of a trading day.\n",
    "- Volume: The total number of shares traded in a day.\n",
    "- Percent change: The difference in price with respect to the original price, as a percentage.\n",
    "\n",
    "To make requests to the aforementioned API, you will need an API key. In order to get one, you will need to make an account at the website. Once you've signed up, you can use the API key that comes with the free plan. It has a limit of 250 requests per day, which should be more than enough. You will have to encode your API key in the URL that you make requests to; see a complete example of such a request at the right side of the [documentation](https://site.financialmodelingprep.com/developer/docs#Stock-Historical-Price).\n",
    "\n",
    "Implement the following two functions.\n",
    "\n",
    "#### `stock_history`\n",
    "\n",
    "Complete the implementation of the function `stock_history`, which takes in a string `ticker` and two integers, `year` and `month`, and returns a DataFrame containing the price history for that stock in that month. Keep all of the attributes that are returned by the API.\n",
    "\n",
    "***Notes***:\n",
    "- Read the API documentation if you get stuck!\n",
    "- [`pd.date_range`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html) takes in two dates and returns a sequence of all dates between the two dates, excluding the right endpoint. How might this be helpful?\n",
    "- The [`requests.get`](https://docs.python-requests.org/en/master/user/quickstart/) function returns a Response object, not the data itself. Use the `json` method on the Response object to extract the relevant JSON, as we did in Lecture 15 (you don't need to `import json` to do this).\n",
    "- You can instantiate a DataFrame using a sequence of dictionaries.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `stock_stats`\n",
    "\n",
    "Create a function `stock_stats` that takes in a DataFrame outputted by `stock_history` and returns a **tuple** of two numbers:\n",
    "1. The percent change of the stock throughout the month as a **percentage**.\n",
    "2. An estimate of the total transaction volume **in billion of dollars** for that month.\n",
    "\n",
    "Both values in the tuple should be **strings** that contain numbers rounded to two decimal places. Add a plus or minus sign in front of the percent change, and make sure that the total transaction volume string ends in a `'B'`.\n",
    "\n",
    "**To compute the percent change**, use the opening price on the first day of the month as the starting price and the closing price on the last day of the month as the ending price.\n",
    "\n",
    "**To compute the total transaction volume**, assume that on any given day, the average price of a share is the midpoint of the high and low price for that day.\n",
    "\n",
    "$$ \\text{Estimated Total Transaction Volume (in dollars)} = \\text{Volume (number of shares traded)} \\times \\text{Average Price} $$\n",
    "\n",
    "For example, suppose there are only three days in March – March 1st, March 2nd, and March 3rd.\n",
    "\n",
    "If BYND (Beyond Meat) opens at \\\\$4 on March 1st and closes at \\\\$5 on March 3rd, its percent change for the month of March is $$\\frac{\\$5-\\$4}{\\$4} = +25.00\\%$$\n",
    "\n",
    "Suppose the high and low prices and volumes of BYND on each day are given below.\n",
    "- March 1st: high \\\\$5, low \\\\$3, volume 500 million (0.5 billion)\n",
    "- March 2nd: high \\\\$5.5, low \\\\$2.5, volume 1 billion\n",
    "- March 3rd: high \\\\$5.25, low \\\\$4, volume 500 million (0.5 billion)\n",
    "\n",
    "Then, the estimated total transaction volume is\n",
    "$$\\frac{\\$5 + \\$3}{2} \\cdot 0.5 B + \\frac{\\$5.5 + \\$2.5}{2} \\cdot 1 B + \\frac{\\$5.25 + \\$4}{2} \\cdot 0.5 B = 8.3125B$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eecabee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b40eb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e211b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't delete this cell, but do run it -- it is needed for the autograder tests\n",
    "\n",
    "# public test for stock_history\n",
    "history = stock_history('BYND', 2019, 6)\n",
    "\n",
    "# public test for stock_stats\n",
    "stats = stock_stats(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b377bb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d9cbc2",
   "metadata": {},
   "source": [
    "## Question 4 – Comment Threads 🧵\n",
    "\n",
    "You regularly browse [Hacker News](https://news.ycombinator.com/) to keep up with the latest news in tech. One link to a Hacker News article is https://news.ycombinator.com/item?id=18344932. Note that this article has 18 comments and has a `storyid` of 18344932.\n",
    "\n",
    "The problem now is that you don't have internet access on your phone during your morning commute to work, so you want to save the interesting stories' comment threads beforehand in a CSV. You find their [API documentation](https://github.com/HackerNews/API) and decide to get to work.\n",
    "\n",
    "Complete the implementation of the function `get_comments`, which takes in a `storyid` and returns a DataFrame of all the comments below the news story. You can ignore \"dead\" comments(you will know them when you see them), as well as \"dead\" comments’ children. **Make sure the order of the comments in your DataFrame is from top to bottom just as you see on the website**. \n",
    "\n",
    "The DataFrame that `get_comments` returns should have 5 columns:\n",
    "1. `'id'`: The unique ID of the comment.\n",
    "2. `'by'`: The author of the comment.\n",
    "3. `'text'`: The actual comment.\n",
    "4. `'parent'`: The unique ID of the comment this comment is replying to.\n",
    "5. `'time'`: When the comment was created (in `pd.Timestamp` format).\n",
    "\n",
    "Some guidance:\n",
    "1. The URL to make requests to is `'https://hacker-news.firebaseio.com/v0/item/{}.json'`, however, the `{}` should be replaced with the ID of the article or page you are trying to access. \n",
    "2. Again, do not `import json` – instead, use the `json` method on the Response object you get back.\n",
    "3. Use depth-first search when traversing the comments tree. You will have to do this manually, since you cannot use Beautiful Soup (which is only for HTML documents, not JSON objects).\n",
    "4. Make sure the length of your returned DataFrame is the same as value for the `'descendants'` key in the response JSON (both of which correspond to the number of comments for the story).\n",
    "5. You are allowed to use loops in this function. You may also want to create at least one helper function.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    You may find <a href=\"https://www.youtube.com/watch?v=uOfwW-onmpc\"><b>this hint video 🎥</b></a> helpful!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b3a998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eaa337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c1643e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# don't delete this cell, but do run it -- it is needed for the autograder tests\n",
    "comments = get_comments(18344932)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105821df",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5514c94",
   "metadata": {},
   "source": [
    "## Congratulations! You're done with Lab 6! 🏁\n",
    "\n",
    "As a reminder, all of the work you want to submit needs to be in `lab.py`.\n",
    "\n",
    "To verify that all of your work is indeed in `lab.py`, and that you didn't accidentally implement a function in this notebook and not in `lab.py`, we've included another notebook in the lab folder, called `lab-validation.ipynb`. `lab-validation.ipynb` is a version of this notebook with only the `grader.check` cells and the code needed to set up the tests. \n",
    "\n",
    "\n",
    "### **Go to `lab-validation.ipynb`, and go to Kernel > Restart & Run All.** This will check if all `grader.check` test cases pass using just the code in `lab.py`.\n",
    "\n",
    "Once you're able to pass all test cases in `lab-validation.ipynb`, including the call to `grader.check_all()` at the very bottom, then you're ready to submit your `lab.py` to Gradescope. In addition to submitting `lab.py`, you will also need to submit `lab06_1.html` and any local images necessary for rendering your `lab06_1.html` file. Once submitting to Gradescope, make sure to stick around until all test cases pass.\n",
    "\n",
    "There is also a call to `grader.check_all()` below in _this_ notebook, but make sure to also follow the steps above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ac038",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77a723",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> os.path.exists('lab06_1.html')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q01_html = bs4.BeautifulSoup(open(\"lab06_1.html\", encoding='utf-8'))\n>>> len(q01_html.find_all('image')) == 0\nTrue",
         "failure_message": "you should not use the <image> tag to add images",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> extract_book_out[1] == extract_book_url\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(get_product_info_out, dict)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> 'Category' in get_product_info_out.keys()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> get_product_info_out['Rating'] == 'Two'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> scrape_books_out.shape == (1, 11)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> scrape_books_out['Rating'][0] == 'Four'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> scrape_books_out['Title'][0] == 'Sharp Objects'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> history.shape == (20, 13)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> history.label.iloc[-1] == 'June 03, 19'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> (len(stats[0]), len(stats[1])) == (7, 6)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> (float(stats[0][1:-1]) > 30) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> float(stats[1][:-1]) > 1 == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> stats[1][-1] == 'B'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> comments.shape == (18, 5)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> comments.loc[5, 'by'] == 'RobAtticus'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> comments.loc[5, 'time'].day == 31\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
