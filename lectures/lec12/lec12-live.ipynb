{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a44b8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from dsc80_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a387eee",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "salaries = pd.read_csv('https://transcal.s3.amazonaws.com/public/export/san-diego-2021.csv')\n",
    "salaries['Employee Name'] = salaries['Employee Name'].str.split().str[0] + ' Xxxx'\n",
    "\n",
    "jobtitles = salaries['Job Title']\n",
    "jobtitles = jobtitles[jobtitles.notna()]\n",
    "jobtitles = (\n",
    "    jobtitles\n",
    "    .str.lower()\n",
    "    .str.replace(r'\\bto\\b|\\bthe\\b|\\bfor\\b', '', regex=True)\n",
    "    .str.replace('[^A-Za-z0-9 ]', ' ', regex=True)\n",
    "    .str.replace(' +', ' ', regex=True)               # ' +' matches 1 or more occurrences of a space.\n",
    "    .str.strip()                                      # Removes leading/trailing spaces if present.\n",
    ")\n",
    "\n",
    "unique_words = pd.Series(jobtitles.str.split().sum()).value_counts()\n",
    "\n",
    "# Created using a dictionary to avoid a \"DataFrame is highly fragmented\" warning.\n",
    "counts_dict = {}\n",
    "for word in unique_words.index:\n",
    "    re_pat = fr'\\b{word}\\b'\n",
    "    counts_dict[word] = jobtitles.str.count(re_pat).astype(int).tolist()\n",
    "    \n",
    "counts_df = pd.DataFrame(counts_dict).set_index(jobtitles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca51859",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 12 ‚Äì Text Features\n",
    "\n",
    "## DSC 80, Fall 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22824200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üì£ Announcements üì£\n",
    "\n",
    "- Project 3 due Friday.\n",
    "- Lab 7 out, due Monday, Nov 20.\n",
    "- 116 / 153 = 76% of students filled out the Mid-quarter survey. Thanks for your responses!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd851d5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üìÜ Agenda\n",
    "\n",
    "- [ ] Bag of words\n",
    "- [ ] Cosine similarity\n",
    "- [ ] TF-IDF\n",
    "    - [ ] Example: State of the Union addresses üé§."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152e40a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üìù Mid-Quarter Survey\n",
    "\n",
    "- Overall high satisfaction with the course so far.\n",
    "    - Higher workload, but not beyond what we expected going in.\n",
    "- Assignment wordings could be more clear (e.g. Lab 4).\n",
    "    - We have a long list of changes we want to make to assignments based on your feedback during OH, we're working on improving the assignments for next quarter.\n",
    "- 25% of class can't attend any scheduled OH.\n",
    "    - Will ask staff to see whether other times are available.\n",
    "- Lecture pace is fast!\n",
    "    - DSC 80 covers a LOT of material.\n",
    "    - I'll walk through more small examples, and sketch out approach to code\n",
    "    - I'll include a Slido for every lecture for Q&A, send questions to slow me down!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c80be0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üôãüôãüèΩ‚Äç‚ôÄÔ∏è Slido\n",
    "\n",
    "https://app.sli.do/event/2LZSnXWNpGPiuVnCZMa5J8\n",
    "\n",
    "<center><img src=\"imgs/slido.svg\" width=\"30%\"></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ff5ce7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bag of words üí∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1c6106",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: San Diego employee salaries\n",
    "\n",
    "Recall, we're working with a (real) dataset of salary data for all San Diego city employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347ff104",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "jobtitles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa84920",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Text similarity\n",
    "\n",
    "Recall, our idea is to measure the similarity of two job titles by counting the number of shared words between the job titles. How do we actually do that, for all of the job titles we have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b462b66",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A counts matrix\n",
    "\n",
    "Let's create a \"counts\" matrix, such that:\n",
    "- there is 1 row per job title,\n",
    "- there is 1 column per **unique** word that is used in job titles, and\n",
    "- the value in row `title` and column `word` is the number of occurrences of `word` in `title`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62f0ec6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Such a matrix might look like:\n",
    "\n",
    "| | senior | lecturer | teaching | professor | assistant | associate |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| **senior lecturer** | 1 | 1 | 0 | 0 | 0 | 0 |\n",
    "| **assistant teaching professor** | 0 | 0 | 1 | 1 | 1 | 0 | \n",
    "| **associate professor** | 0 | 0 | 0 | 1 | 0 | 1 |\n",
    "| **senior assistant to the assistant professor** | 1 | 0 | 0 | 1 | 2 | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea899f5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating a counts matrix\n",
    "\n",
    "First, we need to determine all words that are used across all job titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de1dbb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd6d0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "455b1fab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next, to determine the columns of our matrix, we need to find a list of all **unique** words used in titles. We can do this with `np.unique`, but `value_counts` shows us the distribution, which is interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346850eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = ...\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605c27fa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that in `unique_words.index`, job titles are sorted by number of occurrences!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9d3869",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For each of the 327 unique words that are used in job titles, we can count the number of occurrences of the word in each job title.\n",
    "- `'deputy fire chief'` contains the word `'deputy'` once, the word `'fire'` once, and the word `'chief'` once.\n",
    "- `'assistant managers assistant'` contains the word `'assistant'` twice and the word `'managers'` once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe1abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created using a dictionary to avoid a \"DataFrame is highly fragmented\" warning.\n",
    "counts_dict = {}\n",
    "\n",
    "...\n",
    "\n",
    "counts_df = pd.DataFrame(counts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea26cb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11932e2",
   "metadata": {},
   "source": [
    "`counts_df` has one row for all 12303 employees, and one column for each unique word that is used in a job title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae90ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5470f68",
   "metadata": {},
   "source": [
    "To put into context what the numbers in `counts_df` mean, we can show the actual job title for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c2d3f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts_df = counts_df.set_index(jobtitles)\n",
    "counts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2d1081",
   "metadata": {},
   "source": [
    "The fourth row tells us that the fourth job title contains `'police'` once and `'officer'` once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7497e4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interpreting the counts matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00cd6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f240158",
   "metadata": {},
   "source": [
    "The Series below describes the 20 most common words used in job titles, along with the number of times they appeared in all job titles (including repeats). We will call these words \"top 20\" words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd3dac3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remember, the columns of counts_df are ordered by number of occurrences.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cbee97",
   "metadata": {},
   "source": [
    "The Series below describes the **number of top 20 words** used in each job title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a055ab2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8769612f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Question: What job titles are most similar to `'deputy fire chief'`?\n",
    "\n",
    "- Remember, our idea was to count the number of shared words between two job titles.\n",
    "\n",
    "- We now have access to `counts_df`, which contains a row vector for each job title.\n",
    "\n",
    "- How can we use it to count the number of shared words between two job titles, i.e. the **similarity** of two job titles?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abeb42b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To start, let's compare the row vectors for `'deputy fire chief'` and `'fire battalion chief'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730f1fb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfc = counts_df.loc['deputy fire chief'].iloc[0]\n",
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c56a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fbc = counts_df.loc['fire battalion chief'].iloc[0]\n",
    "fbc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cbbcd2",
   "metadata": {},
   "source": [
    "We can stack these two vectors horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557eb8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_counts = (\n",
    "    pd.concat([dfc, fbc], axis=1)\n",
    "    .sort_values(by=['deputy fire chief', 'fire battalion chief'], ascending=False)\n",
    "    .head(10)\n",
    "    .T\n",
    ")\n",
    "\n",
    "pair_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb1144b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One way to measure how similar the above two vectors are is through their **dot product**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e6d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d829862d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here, since both vectors consist only of 1s and 0s, the dot product is equal to the **number of shared words** between the two job titles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3efce65",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The dot product\n",
    "\n",
    "- Recall, if $\\vec{a} = \\begin{bmatrix} a_1 & a_2 & ... & a_n \\end{bmatrix}^T$ and $\\vec{b} = \\begin{bmatrix} b_1 & b_2 & ... & b_n \\end{bmatrix}^T$ are two vectors, then their **dot product** $\\vec{a} \\cdot \\vec{b}$ is defined as:\n",
    "\n",
    "$$\\vec{a} \\cdot \\vec{b} = a_1b_1 + a_2b_2 + ... + a_nb_n$$\n",
    "\n",
    "- The dot product also has a **geometric** interpretation. If $|\\vec{a}|$ and $|\\vec{b}|$ are the $L_2$ norms (lengths) of $\\vec{a}$ and $\\vec{b}$, and $\\theta$ is the angle between $\\vec{a}$ and $\\vec{b}$, then:\n",
    "\n",
    "$$\\vec{a} \\cdot \\vec{b} = |\\vec{a}| |\\vec{b}| \\cos \\theta$$\n",
    "\n",
    "<center><img src='imgs/dot-prod.png' width=20%>(<a href=\"https://byjus.com/physics/scalar-and-vector-products/\">source</a>)</center>\n",
    "\n",
    "- $\\cos \\theta$ is equal to its maximum value (1) when $\\theta = 0$, i.e. when $\\vec{a}$ and $\\vec{b}$ point in the same direction. \n",
    "\n",
    "- üö® **Key idea: The more similar two unit vectors are, the larger their dot product is!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d041d25",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing similarities\n",
    "\n",
    "To find the job title that is most similar to `'deputy fire chief'`, we can compute the dot product of the `'deputy fire chief'` word vector with all other titles' word vectors, and find the title with the highest dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff15953",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55504644",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ab9f8f",
   "metadata": {},
   "source": [
    "To do so, we can apply `np.dot` to each row that doesn't correspond to `'deputy fire chief'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a887fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dots = (\n",
    "    ...\n",
    ")\n",
    "\n",
    "dots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def81254",
   "metadata": {},
   "source": [
    "The unique job titles that are **most similar** to `'deputy fire chief'` are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c3c2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955afa7d",
   "metadata": {},
   "source": [
    "Note that they all share two words in common with `'deputy fire chief'`.\n",
    "\n",
    "**Note:** To truly use the dot product as a measure of similarity, we should **normalize** by the lengths of the word vectors. More on this soon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af4957",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üôãüôãüèΩ‚Äç‚ôÄÔ∏è Questions?\n",
    "\n",
    "https://app.sli.do/event/2LZSnXWNpGPiuVnCZMa5J8\n",
    "\n",
    "<center><img src=\"imgs/slido.svg\" width=\"30%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccb0ce4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bag of words\n",
    "\n",
    "- The **bag of words** model represents texts (e.g. job titles, sentences, documents) as **vectors of word counts**.\n",
    "    - The \"counts\" matrices we have worked with so far were created using the bag of words model.\n",
    "    - The bag of words model defines a **vector space** in $\\mathbb{R}^{\\text{number of unique words}}$.\n",
    "- It is called \"bag of words\" because it doesn't consider **order**.\n",
    "\n",
    "<center><img src='imgs/bag-of-words.jpeg' width=45%></center>\n",
    "\n",
    "<center><a href=\"https://42f6861cgkip12ijm63i3orf-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/2020-07-bagofwords.jpg\">(source)</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2399af24",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: Interactive bag of words demo\n",
    "\n",
    "Check [this](https://svelte.dev/repl/98d158ef6fb842d09c66ed20b9a31e99?version=3.55.1) site out ‚Äì it automatically generates a bag of words matrix for you!\n",
    "\n",
    "<center><img src='imgs/bow-interactive.png' width=50%>(<a href=\"https://twitter.com/jdwlbr/status/1622704535511916544?s=20\">source</a>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c05ead",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53050912",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cosine similarity and bag of words\n",
    "\n",
    "To measure the similarity between two word vectors, we compute their **normalized** dot product, also known as their **cosine similarity**.\n",
    "\n",
    "$$\\cos \\theta = \\boxed{\\frac{\\vec{a} \\cdot \\vec{b}}{|\\vec{a}| | \\vec{b}|}}$$\n",
    "\n",
    "If $\\cos \\theta$ is large, the two word vectors are similar. **It is important to normalize by the lengths of the vectors**, otherwise texts with more words will have artificially high similarities with other texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7906fca2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Note:** Sometimes, you will see the **cosine distance** being used. It is the complement of cosine similarity:\n",
    "  \n",
    "  $$\\text{dist}(\\vec{a}, \\vec{b}) = 1 - \\cos \\theta$$\n",
    "  \n",
    "If $\\text{dist}(\\vec{a}, \\vec{b})$ is small, the two word vectors are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef9257",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A recipe for computing similarities\n",
    "\n",
    "Given a set of documents, to find the **most similar** text to one _document_ $d$ in particular:\n",
    "\n",
    "- Use the bag of words model to create a counts matrix, in which:\n",
    "    - there is 1 row per document,\n",
    "    - there is 1 column per **unique** word that is used across documents, and\n",
    "    - the value in row `doc` and column `word` is the number of occurrences of `word` in `doc`.\n",
    "\n",
    "- Compute the cosine similarity between $d$'s row vector and all other documents' row vectors.\n",
    "\n",
    "- The other document with the greatest cosine similarity is the most similar, under the bag of words model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81897bc1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Global warming üåé\n",
    "\n",
    "Consider the following three documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605cfd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.Series([\n",
    "    'I really really want global peace',\n",
    "    'I must enjoy global warming',\n",
    "    'We must solve climate change'\n",
    "])\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b1a1e4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's represent each document using the bag of words model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8f0768",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = ...\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c734f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_dict = {}\n",
    "\n",
    "...\n",
    "\n",
    "counts_df = pd.DataFrame(counts_dict).set_index(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec7b9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf36677a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's now find the cosine similarity between each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c87ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b30ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_pair(s1, s2):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f77468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the documentation of the .corr method to see how this works!\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ee569a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Issue:** Bag of words only encodes the **words** that each document uses, not their **meanings**.\n",
    "- \"I really really want global peace\" and \"We must solve climate change\" have similar meanings, but have no shared words, and thus a low cosine similarity.\n",
    "- \"I really really want global peace\" and \"I must enjoy global warming\" have very different meanings, but a relatively high cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de88443",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pitfalls of the bag of words model\n",
    "\n",
    "Remember, the key assumption underlying the bag of words model is that **two documents are similar if they share many words in common**.\n",
    "\n",
    "- The bag of words model doesn't consider **order**.\n",
    "    - The job titles `'deputy fire chief'` and `'chief fire deputy'` are treated as the same.\n",
    "\n",
    "- The bag of words model doesn't consider the **meaning** of words.\n",
    "    - `'I love data science'` and `'I hate data science'` share 75% of their words, but have very different meanings.\n",
    "\n",
    "- The bag of words model treats all words as being equally important.\n",
    "    - `'deputy'` and `'fire'` have the same importance, even though `'fire'` is probably more important in describing someone's job title.\n",
    "    - <span style=\"color:red\"><b>Let's address this point.</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124a65b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üôãüôãüèΩ‚Äç‚ôÄÔ∏è Questions?\n",
    "\n",
    "https://app.sli.do/event/2LZSnXWNpGPiuVnCZMa5J8\n",
    "\n",
    "<center><img src=\"imgs/slido.svg\" width=\"30%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08543520",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc3cdc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The importance of words\n",
    "\n",
    "**Issue:** The bag of words model doesn't know which words are \"important\" in a document. Consider the following document:\n",
    "\n",
    "<center>\"my brother has a friend named <b>billy</b> who has an uncle named <b>billy</b>\"</center>\n",
    "\n",
    "How do we determine which words are important?\n",
    "- The most common words (\"the\", \"has\") often **don't** have much meaning!\n",
    "- The very rare words are also less important!\n",
    "\n",
    "**Goal:** Find a way of quantifying the importance of a word in a document by **balancing the above two factors**, i.e. find the word that **best summarizes** a document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4d0ca0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Term frequency\n",
    "\n",
    "- The **term frequency** of a word (term) $t$ in a document $d$, denoted $\\text{tf}(t, d)$ is the proportion of words in document $d$ that are equal to $t$.\n",
    "\n",
    "$$\\text{tf}(t, d) = \\frac{\\text{# of occurrences of $t$ in $d$}}{\\text{total # of words in $d$}}$$\n",
    "\n",
    "- **Example:** What is the term frequency of \"billy\" in the following document?\n",
    "\n",
    "<center>\"my brother has a friend named <b>billy</b> who has an uncle named <b>billy</b>\"</center>\n",
    "\n",
    "- **Answer:** $\\frac{2}{13}$.\n",
    "\n",
    "- Intuition: Words that occur often within a document are important to the document's meaning.\n",
    "    - If $\\text{tf}(t, d)$ is large, then word $t$ occurs often in $d$.\n",
    "    - If $\\text{tf}(t, d)$ is small, then word $t$ does not occur often $d$.\n",
    "\n",
    "- Issue: \"has\" also has a TF of $\\frac{2}{13}$, but it seems less important than \"billy\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0cb0c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inverse document frequency\n",
    "\n",
    "- The **inverse document frequency** of a word $t$ in a set of documents $d_1, d_2, ...$ is\n",
    "\n",
    "$$\\text{idf}(t) = \\log \\left(\\frac{\\text{total # of documents}}{\\text{# of documents in which $t$ appears}} \\right)$$\n",
    "\n",
    "- **Example:** What is the inverse document frequency of \"billy\" in the following three documents?\n",
    "    - \"my brother has a friend named **billy** who has an uncle named **billy**\"\n",
    "    - \"my favorite artist is named jilly boel\"\n",
    "    - \"why does he talk about someone named **billy** so often\"\n",
    "\n",
    "- **Answer:** $\\log \\left(\\frac{3}{2}\\right) \\approx 0.4055$.\n",
    "\n",
    "- Intuition: If a word appears in every document (like \"the\" or \"has\"), it is probably not a good summary of any one document.\n",
    "    - If $\\text{idf}(t)$ is large, then $t$ is rarely found in documents.\n",
    "    - If $\\text{idf}(t)$ is small, then $t$ is commonly found in documents.\n",
    "    - Think of $\\text{idf}(t)$ as the \"rarity factor\" of $t$ across documents ‚Äì the larger $\\text{idf}(t)$ is, the more rare $t$ is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5ce4c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Intuition\n",
    "\n",
    "$$\\text{tf}(t, d) = \\frac{\\text{# of occurrences of $t$ in $d$}}{\\text{total # of words in $d$}}$$\n",
    "\n",
    "$$\\text{idf}(t) = \\log \\left(\\frac{\\text{total # of documents}}{\\text{# of documents in which $t$ appears}} \\right)$$\n",
    "\n",
    "**Goal:** Quantify how well word $t$ **summarizes** document $d$.\n",
    "\n",
    "- If $\\text{tf}(t, d)$ is small, then $t$ doesn't occur very often in $d$, so $t$ can't be a good summary of $d$.\n",
    "\n",
    "- If $\\text{idf}(t)$ is small, then $t$ occurs often amongst all documents, and so it is not a good summary of any one document.\n",
    "\n",
    "- If $\\text{tf}(t, d)$ and $\\text{idf}(t)$ are both large, then **$t$ occurs often in $d$ but rarely overall**. This makes $t$ **a good summary** of document $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3c7776",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Term frequency-inverse document frequency\n",
    "\n",
    "The **term frequency-inverse document frequency (TF-IDF)** of word $t$ in document $d$ is the product:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\\text{tfidf}(t, d) &= \\text{tf}(t, d) \\cdot \\text{idf}(t) \\\\\\ &= \\frac{\\text{# of occurrences of $t$ in $d$}}{\\text{total # of words in $d$}} \\cdot \\log \\left(\\frac{\\text{total # of documents}}{\\text{# of documents in which $t$ appears}} \\right) \\end{align*} $$\n",
    "\n",
    "- If $\\text{tfidf}(t, d)$ is large, then $t$ is a good summary of $d$, because $t$ occurs often in $d$ but rarely across all documents.\n",
    "\n",
    "- TF-IDF is a **heuristic** ‚Äì it has no probabilistic justification.\n",
    "\n",
    "- To know if $\\text{tfidf}(t, d)$ is large for one particular word $t$, we need to compare it to $\\text{tfidf}(t_i, d)$, for several different words $t_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef231326",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing TF-IDF\n",
    "\n",
    "**Question:** What is the TF-IDF of \"global\" in the second sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8388d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83e7306",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc50973a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccb3ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1210e55d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da3e1607",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Question:** Is this big or small? Is \"global\" the **best** summary of the second sentence?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af81a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### TF-IDF of all words in all documents\n",
    "\n",
    "On its own, the TF-IDF of a word in a document doesn't really tell us anything; we must compare it to TF-IDFs of other words in that same document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389d19a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c19824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_dict = {}\n",
    "\n",
    "...\n",
    "\n",
    "tfidf = pd.DataFrame(tfidf_dict).set_index(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a00f89d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d39de10",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interpreting TF-IDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e5f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734cadb3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The above DataFrame tells us that:\n",
    "- the TF-IDF of `'peace'` in the first sentence is 0.183102,\n",
    "- the TF-IDF of `'climate'` in the second sentence is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cafb1ed",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that there are two ways that $\\text{tfidf}(t, d) = \\text{tf}(t, d) \\cdot \\text{idf}(t)$ can be 0:\n",
    "- If $t$ appears in every document, because then $\\text{idf}(t) = \\log (\\frac{\\text{# documents}}{\\text{# documents}}) = \\log(1) = 0$.\n",
    "- If $t$ does not appear in document $d$, because then $\\text{tf}(t, d) = \\frac{0}{\\text{len}(d)} = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6af48d5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The word that **best summarizes** a document is the word with the highest TF-IDF for that document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee6b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f3cbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "804d8e94",
   "metadata": {},
   "source": [
    "Look closely at the rows of `tfidf` ‚Äì in documents 2 and 3, the max TF-IDF is not unique!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b6fcc0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üôãüôãüèΩ‚Äç‚ôÄÔ∏è Questions?\n",
    "\n",
    "https://app.sli.do/event/2LZSnXWNpGPiuVnCZMa5J8\n",
    "\n",
    "<center><img src=\"imgs/slido.svg\" width=\"30%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b92963d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: State of the Union addresses üé§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980d913",
   "metadata": {},
   "source": [
    "### State of the Union addresses\n",
    "\n",
    "The 2023 State of the Union address was on February 7th, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d40e0a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('gzcBTUvVp7M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec32713",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db49b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "sotu_txt = Path('data') / 'stateoftheunion1790-2023.txt'\n",
    "sotu = sotu_txt.read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05569714",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sotu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66057eca",
   "metadata": {},
   "source": [
    "The entire **corpus** (another word for \"set of documents\") is over 10 million characters long... let's not display it in our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a987af22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sotu[:1600])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a60c4f",
   "metadata": {},
   "source": [
    "Each speech is separated by `'***'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d60dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = sotu.split('\\n***\\n')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca0971",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(speeches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723eec4",
   "metadata": {},
   "source": [
    "Note that each \"speech\" currently contains other information, like the name of the president and the date of the address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427d8ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dea89846",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's extract just the speech text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa932c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_struct(speech):\n",
    "    L = speech.strip().split('\\n', maxsplit=3)\n",
    "    L[3] = re.sub(r\"[^A-Za-z' ]\", ' ', L[3]).lower()\n",
    "    return dict(zip(['speech', 'president', 'date', 'contents'], L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5438e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speeches_df = pd.DataFrame(list(map(extract_struct, speeches)))\n",
    "speeches_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df1fade",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding the most important words in each speech\n",
    "\n",
    "Here, a \"document\" is a speech. We have 233 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5a1d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926bcc2d",
   "metadata": {},
   "source": [
    "A rough sketch of what we'll compute:\n",
    "\n",
    "```\n",
    "for each word t:\n",
    "    for each speech d:\n",
    "        compute tfidf(t, d)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d40a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = speeches_df['contents'].str.split().explode().value_counts()\n",
    "# Take the top 500 most common words for speed\n",
    "unique_words = unique_words.iloc[:500].index\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96cdc6e",
   "metadata": {},
   "source": [
    "### üí° Pro-Tip: Using `tqdm`\n",
    "\n",
    "This code takes a while to run, so we'll use the `tdqm` package to track its progress. (Install with `pip install tqdm` if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1451a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tfidf_dict = {}\n",
    "tf_denom = ...\n",
    "\n",
    "# Wrap the sequence with `tqdm()` to display a progress bar\n",
    "for word in tqdm(unique_words):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a8867",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = pd.DataFrame(tfidf_dict)\n",
    "tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f34b9e",
   "metadata": {},
   "source": [
    "Note that the TF-IDFs of many common words are all 0!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c15f5bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summarizing speeches\n",
    "\n",
    "By using `idxmax`, we can find the word with the highest TF-IDF in each speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b7f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = ...\n",
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aad3811",
   "metadata": {},
   "source": [
    "What if we want to see the 5 words with the highest TF-IDFs, for each speech?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbdd477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_largest(row):\n",
    "    return list(row.index[row.argsort()][-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = tfidf.apply(five_largest, axis=1)\n",
    "keywords_df = pd.concat([\n",
    "    speeches_df['president'],\n",
    "    speeches_df['date'],\n",
    "    keywords\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7762dd5e",
   "metadata": {},
   "source": [
    "Run the cell below to see every single row of `keywords_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf737b3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_df(keywords_df, rows=233)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847a013b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: What if we remove the $\\log$ from $\\text{idf}(t)$?\n",
    "\n",
    "Let's try it and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cfb892",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_nl_dict = {}\n",
    "tf_denom = speeches_df['contents'].str.split().str.len()\n",
    "\n",
    "for word in tqdm(unique_words):\n",
    "    re_pat = fr' {word} ' # Imperfect pattern for speed.\n",
    "    tf = speeches_df['contents'].str.count(re_pat) / tf_denom\n",
    "    idf_nl = len(speeches_df) / speeches_df['contents'].str.contains(re_pat).sum()\n",
    "    tfidf_nl_dict[word] =  tf * idf_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdd2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_nl = pd.DataFrame(tfidf_nl_dict)\n",
    "tfidf_nl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54838d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_nl = tfidf_nl.apply(five_largest, axis=1)\n",
    "keywords_nl_df = pd.concat([\n",
    "    speeches_df['president'],\n",
    "    speeches_df['date'],\n",
    "    keywords_nl\n",
    "], axis=1)\n",
    "keywords_nl_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64da969",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The role of $\\log$ in $\\text{idf}(t)$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\\text{tfidf}(t, d) &= \\text{tf}(t, d) \\cdot \\text{idf}(t) \\\\\\ &= \\frac{\\text{# of occurrences of $t$ in $d$}}{\\text{total # of words in $d$}} \\cdot \\log \\left(\\frac{\\text{total # of documents}}{\\text{# of documents in which $t$ appears}} \\right) \\end{align*} $$\n",
    "- Remember, for any positive input $x$, $\\log(x)$ is (much) smaller than $x$.\n",
    "- In $\\text{idf}(t)$, the $\\log$ \"dampens\" the impact of the ratio $\\frac{\\text{# documents}}{\\text{# documents with $t$}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d012ae6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If a word is very common, the ratio will be close to 1. The log of the ratio will be close to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46db591",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1000 / 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dc22dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(1000 / 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e66ce75",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If a word is very common (e.g. 'the'), removing the log multiplies the statistic by a large factor.\n",
    "- If a word is very rare, the ratio will be very large. However, for instance, a word being seen in **2 out of 50** documents is not very different than being seen in **2 out of 500** documents (it is very rare in both cases), and so $\\text{idf}(t)$ should be similar in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b376f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(50 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfc1dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(500 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(50 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3643c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(500 / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b1fe83",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üôãüôãüèΩ‚Äç‚ôÄÔ∏è Questions?\n",
    "\n",
    "https://app.sli.do/event/2LZSnXWNpGPiuVnCZMa5J8\n",
    "\n",
    "<center><img src=\"imgs/slido.svg\" width=\"30%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269efd96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934fb660",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- One way to turn documents, like `'deputy fire chief'`, into feature vectors, is to count the number of occurrences of each word in the document, ignoring order. This is done using the **bag of words** model.\n",
    "- To measure the similarity of two documents under the bag of words model, compute the cosine similarity of their two word vectors.\n",
    "- Term frequency-inverse document frequency (TF-IDF) is a statistic that tries to quantify how **important** a word (term) is to a document. It balances:\n",
    "    - **how often a word appears in a particular document**, $\\text{tf}(t, d)$, with\n",
    "    - **how often a word appears across documents**, $\\text{idf}(t)$.\n",
    "- For a given document, the word with the highest TF-IDF is thought to \"best summarize\" that document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62dad56",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "Modeling and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77285388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
