{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a44b8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from dsc80_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff2b2f7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# The dataset is built into plotly (and seaborn)!\n",
    "# We shuffle here so that the head of the DataFrame contains rows where smoker is Yes and smoker is No,\n",
    "# purely for illustration purposes (it doesn't change any of the math).\n",
    "np.random.seed(1)\n",
    "tips = px.data.tips().sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f3172e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def rmse(actual, pred):\n",
    "    return np.sqrt(np.mean((actual - pred) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca51859",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 14 ‚Äì Feature Engineering, Pipelines\n",
    "\n",
    "## DSC 80, Fall 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22824200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üì£ Announcements üì£\n",
    "\n",
    "- Project 4 out, due next Friday, Dec 1.\n",
    "    - No project checkpoint due because of Thanksgiving, so everyone gets full credit for the checkpoint!\n",
    "    - But start early! Historically, the last two questions of the project take up about 75% of the project time.\n",
    "- Lab 8 out, due Nov 27.\n",
    "- No lecture / discussion / OH on Thurs or Fri. Happy Thanksgiving! ü¶É"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd851d5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üìÜ Agenda\n",
    "\n",
    "- [ ] Review: Linear models for restaurant tips\n",
    "- [ ] Feature engineering\n",
    "- [ ] Scikit-learn pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398eb093",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üôãüôãüèΩ‚Äç‚ôÄÔ∏è Slido\n",
    "\n",
    "https://app.sli.do/event/2LZSnXWNpGPiuVnCZMa5J8\n",
    "\n",
    "<center><img src=\"imgs/slido.svg\" width=\"30%\"></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce21ea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review: Linear Models for Restaurant tips üßë‚Äçüç≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3cdc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3b5f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "mean_tip = tips['tip'].mean()\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X=tips[['total_bill']], y=tips['tip'])\n",
    "\n",
    "model_two = LinearRegression()\n",
    "model_two.fit(X=tips[['total_bill', 'size']], y=tips['tip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca68d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dict = {}\n",
    "rmse_dict['constant tip amount'] = rmse(tips['tip'], mean_tip)\n",
    "\n",
    "all_preds = model.predict(tips[['total_bill']])\n",
    "rmse_dict['one feature: total bill'] = rmse(tips['tip'], all_preds)\n",
    "\n",
    "rmse_dict['two features'] = rmse(\n",
    "    tips['tip'], model_two.predict(tips[['total_bill', 'size']])\n",
    ")\n",
    "rmse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10277e74",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Calculating $R^2$\n",
    "\n",
    "`all_preds` contains `model_two`'s predicted `'tip'` for every row in `tips`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb68507b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = tips.assign(predicted=model_two.predict(tips[['total_bill', 'size']]))\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57861383",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Method 1: $R^2 = \\frac{\\text{var}(\\text{predicted $y$ values})}{\\text{var}(\\text{actual $y$ values})}$**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2213f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(pred['predicted']) / np.var(pred['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011a91f3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Method 2:** $R^2 = \\left[ \\text{correlation}(\\text{predicted $y$ values}, \\text{actual $y$ values}) \\right]^2$\n",
    "\n",
    "Note: By correlation here, we are referring to $r$, the same correlation coefficient you saw in DSC 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70b1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There was a typo here last lecture, the correct code is:\n",
    "(np.corrcoef(pred['predicted'], pred['tip'])) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64fe309",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Method 3:** `LinearRegression.score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ffe7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_two.score(tips[['total_bill', 'size']], tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d3f084",
   "metadata": {},
   "source": [
    "All three methods provide the same result!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe9967",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What's next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7153988b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- So far, in our journey to predict `'tip'`, we've only used the existing numerical features in our dataset, `'total_bill'` and `'size'`.\n",
    "\n",
    "- There's a lot of information in tips that we didn't use ‚Äì `'sex'`, `'smoker'`, `'day'`, and `'time'`, for example. We can't use these features in their current form, because they're non-numeric.\n",
    "\n",
    "- **How do we use categorical features in a regression model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591b777e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature engineering ‚öôÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b929487",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The goal of feature engineering\n",
    "\n",
    "- **Feature engineering** is the act of finding **transformations** that transform data into effective **quantitative variables**.\n",
    "\n",
    "- A feature function $\\phi$ (phi, pronounced \"fea\") is a mapping from raw data to $d$-dimensional space, i.e. $\\phi: \\text{raw data} \\rightarrow \\mathbb{R}^d$.\n",
    "    - If two observations $x_i$ and $x_j$ are \"similar\" in the raw data space, then $\\phi(x_i)$ and $\\phi(x_j)$ should also be \"similar.\"\n",
    "\n",
    "\n",
    "- A \"good\" choice of features depends on many factors:\n",
    "    - The kind of data (quantitative, ordinal, nominal).\n",
    "    - The relationship(s) and association(s) being modeled.\n",
    "    - The model type (e.g. linear models, decision tree models, neural networks)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e155a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One hot encoding\n",
    "\n",
    "- One hot encoding is a transformation that turns a categorical feature into several binary features.\n",
    "\n",
    "- Suppose column `'col'` has $N$ unique values, $A_1$, $A_2$, ..., $A_N$. For each unique value $A_i$, we define the following **feature function**:\n",
    "\n",
    "$$\\phi_i(x) = \\left\\{\\begin{array}{ll}1 & {\\rm if\\ } x = A_i \\\\ 0 &  {\\rm if\\ } x\\neq A_i \\\\ \\end{array}\\right. $$\n",
    "\n",
    "- Note that 1 means \"yes\" and 0 means \"no\".\n",
    "\n",
    "- One hot encoding is also called \"dummy encoding\", and $\\phi(x)$ may also be referred to as an \"indicator variable\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc658794",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: One hot encoding `'smoker'`\n",
    "\n",
    "For each unique value of `'smoker'` in our dataset, we must create a column for just that `'smoker'`. (Remember, `'smoker'` is `'Yes'` when the table was in the smoking section of the restaurant and `'No'` otherwise.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa6f9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870321c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1e3c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "615ccee7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model #4: Multiple linear regression using total bill, table size, and smoker status\n",
    "\n",
    "Now that we've converted `'smoker'` to a numerical variable, we can use it as input in a regression model. Here's the model we'll try to fit:\n",
    "\n",
    "$$\\text{predicted tip} = w_0 + w_1 \\cdot \\text{total bill} + w_2 \\cdot \\text{table size} + w_3 \\cdot \\text{smoker == Yes}$$\n",
    "\n",
    "**Subtlety**: There's no need to use _both_ `'smoker == No'` and `'smoker == Yes'`. If we know the value of one, we already know the value of the other. We can use either one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f8c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_three = LinearRegression()\n",
    "model_three.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c29f19",
   "metadata": {},
   "source": [
    "The following cell gives us our $w^*$s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c1c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00685cb8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Thus, our trained linear model to predict tips given total bills, table sizes, and smoker status (yes or no) is:\n",
    "\n",
    "$$\\text{predicted tip} = 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size} - 0.083 \\cdot \\text{smoker == Yes}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a31b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing Model #4\n",
    "\n",
    "Our new fit model is:\n",
    "\n",
    "$$\\text{predicted tip} = 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size} - 0.083 \\cdot \\text{smoker == Yes}$$\n",
    "\n",
    "To visualize our data and linear model, we'd need 4 dimensions:\n",
    "- One for total bill\n",
    "- One for table size\n",
    "- One for `'smoker == Yes'`.\n",
    "- One for tip.\n",
    "\n",
    "Humans can't visualize in 4D, but there may be a solution. We know that `'smoker == Yes'` only has two possible values, 1 or 0, so let's look at those cases separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0f67d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Case 1**: `'smoker == Yes'` is 1, meaning that the table **was** in the smoking section.\n",
    "\n",
    "$$\\begin{align*} \\text{predicted tip} &= 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size} - 0.083 \\cdot 1 \\\\ &= 0.626 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size}  \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac8dde",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Case 2**: `'smoker == Yes'` is 0, meaning that the table **was not** in the smoking section.\n",
    "\n",
    "$$\\begin{align*} \\text{predicted tip} &= 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size} - 0.083 \\cdot 0 \\\\ &= 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size}  \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e760d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Key idea**: These are two parallel planes in 3D, with different $z$-intercepts!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe3f2ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that the two planes are very close to one another ‚Äì you'll have to zoom in to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d205c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX, YY = np.mgrid[0:50:2, 0:8:1]\n",
    "Z_0 = model_three.intercept_ + model_three.coef_[0] * XX + model_three.coef_[1] * YY + model_three.coef_[2] * 0\n",
    "Z_1 = model_three.intercept_ + model_three.coef_[0] * XX + model_three.coef_[1] * YY + model_three.coef_[2] * 1\n",
    "plane_0 = go.Surface(x=XX, y=YY, z=Z_0, colorscale='Greens')\n",
    "plane_1 = go.Surface(x=XX, y=YY, z=Z_1, colorscale='Purples')\n",
    "\n",
    "fig = go.Figure(data=[plane_0, plane_1])\n",
    "\n",
    "tips_0 = tips[tips['smoker'] == 'No']\n",
    "tips_1 = tips[tips['smoker'] == 'Yes']\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=tips_0['total_bill'], \n",
    "                           y=tips_0['size'], \n",
    "                           z=tips_0['tip'], mode='markers', marker = {'color': 'green'}))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=tips_1['total_bill'], \n",
    "                           y=tips_1['size'], \n",
    "                           z=tips_1['tip'], mode='markers', marker = {'color': 'purple'}))\n",
    "\n",
    "fig.update_layout(scene = dict(\n",
    "    xaxis_title='Total Bill',\n",
    "    yaxis_title='Table Size',\n",
    "    zaxis_title='Tip'),\n",
    "  title='Tip vs. Total Bill and Table Size (Green = Non-Smoking Section, Purple = Smoking Section)',\n",
    "    width=1000, height=800,\n",
    "    showlegend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb2302b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we want to visualize in 2D, we need to pick a single feature to place on the $x$-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45adfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=tips['total_bill'], y=tips['tip'], \n",
    "                         mode='markers', name='Original Data'))\n",
    "fig.add_trace(go.Scatter(x=tips['total_bill'], y=model_three.predict(tips[['total_bill', 'size', 'smoker == Yes']]), \n",
    "                         mode='markers', name='Predicted Tips using Total Bill, <br>Table Size, and Smoker Status'))\n",
    "\n",
    "fig.update_layout(showlegend=True, title='Tip vs. Total Bill',\n",
    "                  xaxis_title='Total Bill', yaxis_title='Tip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d6c67",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Despite being a linear model, why **doesn't** this model **look** like a straight line?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba4179d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üôãüôãüèΩ‚Äç‚ôÄÔ∏è Questions?\n",
    "\n",
    "https://app.sli.do/event/2LZSnXWNpGPiuVnCZMa5J8\n",
    "\n",
    "<center><img src=\"imgs/slido.svg\" width=\"30%\"></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36750de2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing Model #4 to earlier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548bc726",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dict['three features'] = rmse(\n",
    "    tips['tip'], \n",
    "    model_three.predict(tips[['total_bill', 'size', 'smoker == Yes']])\n",
    ")\n",
    "rmse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb6ff2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Adding `'smoker == Yes'` decreased the training RMSE of our model, but **barely**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75cdc3b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea8b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2201375c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We've one hot encoded `'smoker'`, but it required a `for`-loop.\n",
    "\n",
    "- Is there an easy way to one hot encode all four categorical columns ‚Äì `'sex'`, `'smoker'`, `'day'`, and `'time'` ‚Äì all at once, without using a `for`-loop?\n",
    "\n",
    "- Yes, using `sklearn.preprocessing`'s `OneHotEncoder`. More on this soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7705f8a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Predicting ratings ‚≠êÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d7777",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Predicting ratings ‚≠êÔ∏è\n",
    "\n",
    "|UID|AGE|STATE|HAS_BOUGHT|REVIEW|\\||RATING|\n",
    "|---|---|---|---|---|---|---|\n",
    "|74|32|NY|True|\"Meh.\"|\\||&#10025;&#10025;|\n",
    "|42|50|WA|True|\"Worked out of the box...\"|\\||&#10025;&#10025;&#10025;&#10025;|\n",
    "|57|16|CA|NULL|\"Hella tots lit yo...\"|\\||&#10025;|\n",
    "|...|...|...|...|...|\\||...|\n",
    "|(int)|(int)|(str)|(bool)|(str)|\\||(str)|\n",
    "\n",
    "- We want to build a multiple regression model that predicts `'RATING'` using the above features.\n",
    "\n",
    "- Why can't we build a model right away? What must we do so that we can build a model?\n",
    "\n",
    "- Some issues: Missing values, emojis and strings instead of numbers, unrelated columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94368ca4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Uninformative features\n",
    "\n",
    "- `'UID'` was likely used to join the user information (e.g., `'AGE'` and `'STATE'`) with some `reviews` dataset.\n",
    "- Even though `'UID'`s are stored as **numbers**, the numerical value of a user's `'UID'` won't help us predict their `'RATING'`.\n",
    "- If we include the `'UID'` feature, our model will find whatever patterns it can between `'UID'`s and `'RATING'`s in the training (observed data).\n",
    "    - This will lead to a lower training RMSE.\n",
    "- However, since there is truly no relationship between `'UID'` and `'RATING'`, this will lead to **worse** model performance on unseen data (bad).\n",
    "- **Transformation:** drop `'UID'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f44c96d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dropping features\n",
    "\n",
    "There are certain scenarios where manually dropping features might be helpful:\n",
    "\n",
    "1. When the features **do not contain information** associated with the prediction task. \n",
    "2. When the feature is **not available at prediction time.**  \n",
    "- The goal of building a model to predict `'RATING'`s is so that we can **predict `'RATING'`s for users who haven't actually made a `'RATING'`s yet**.\n",
    "- As such, our model should only depend on features that we would know before the user makes their `'RATING'`.\n",
    "- For instance, if users only enter `'REVIEW'`s after entering `'RATING'`s, we shouldn't use `'REVIEW'`s as a feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea574cfa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Encoding ordinal features\n",
    "\n",
    "|UID|AGE|STATE|HAS_BOUGHT|REVIEW|\\||RATING|\n",
    "|---|---|---|---|---|---|---|\n",
    "|74|32|NY|True|\"Meh.\"|\\||&#10025;&#10025;|\n",
    "|42|50|WA|True|\"Worked out of the box...\"|\\||&#10025;&#10025;&#10025;&#10025;|\n",
    "|57|16|CA|NULL|\"Hella tots lit yo...\"|\\||&#10025;|\n",
    "|...|...|...|...|...|\\||...|\n",
    "|(int)|(int)|(str)|(bool)|(str)|\\||(str)|\n",
    "\n",
    "How do we encode the `'RATING'` column, an ordinal variable, as a quantitative variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c558ee7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Transformation:** Replace \"number of &#10025;\" with \"number\".\n",
    "    - This is an **ordinal encoding**, a transformation that maps ordinal values to the positive integers in a way that preserves order.\n",
    "    - Example: (freshman, sophomore, junior, senior) -> (0, 1, 2, 3).\n",
    "    - **Important:** This transformation preserves \"distances\" between ratings.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e1898",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ordinal_enc = {\n",
    "    '‚ú©': 1,\n",
    "    '‚ú©‚ú©': 2,\n",
    "    '‚ú©‚ú©‚ú©': 3,\n",
    "    '‚ú©‚ú©‚ú©‚ú©': 4,\n",
    "    '‚ú©‚ú©‚ú©‚ú©‚ú©': 5,\n",
    "}\n",
    "ordinal_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09af853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.DataFrame().assign(RATING=['‚ú©', '‚ú©‚ú©', '‚ú©‚ú©‚ú©', '‚ú©‚ú©', '‚ú©‚ú©‚ú©', '‚ú©', '‚ú©‚ú©‚ú©', '‚ú©‚ú©‚ú©‚ú©', '‚ú©‚ú©‚ú©‚ú©‚ú©'])\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf292ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.replace(ordinal_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cebe95e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Encoding nominal features\n",
    "\n",
    "|UID|AGE|STATE|HAS_BOUGHT|REVIEW|\\||RATING|\n",
    "|---|---|---|---|---|---|---|\n",
    "|74|32|NY|True|\"Meh.\"|\\||&#10025;&#10025;|\n",
    "|42|50|WA|True|\"Worked out of the box...\"|\\||&#10025;&#10025;&#10025;&#10025;|\n",
    "|57|16|CA|NULL|\"Hella tots lit yo...\"|\\||&#10025;|\n",
    "|...|...|...|...|...|\\||...|\n",
    "|(int)|(int)|(str)|(bool)|(str)|\\||(str)|\n",
    "\n",
    "How do we encode the `'STATE'` column, a nominal variable, as a quantitative variable? In other words, how do we turn `'STATE'`s into meaningful numbers?\n",
    "\n",
    "- **Question**: Why can't we use an ordinal encoding, e.g. NY -> 0, WA -> 1?\n",
    "\n",
    "- **Answer**: There is no inherent ordering to states, e.g. WA is not inherently \"more\" of anything than NY.\n",
    "\n",
    "- **We've already seen the correct strategy**: one hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf6cb7e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Horsepower üöó"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b31c6d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The following dataset, built into the `seaborn` plotting library, contains various information about (older) cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74629562",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg = sns.load_dataset('mpg').dropna()\n",
    "mpg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b32614",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We really do mean old:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87771d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b30a172",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's investigate the relationship between `'horsepower'` and `'mpg'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a3bf75",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The relationship between `'horsepower'` and `'mpg'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5268d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = ...\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6887d19e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It appears that there is a negative association between `'horsepower'` and `'mpg'`, though it's not quite linear. \n",
    "\n",
    "\n",
    "- Let's try and fit a simple linear model that uses `'horsepower'` to predict `'mpg'` and see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc08a100",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predicting `'mpg'` using `'horsepower'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d899e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e2d9d1c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What do our predictions look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5922daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_points = pd.DataFrame({'horsepower': [25, 225]})\n",
    "fig = px.scatter(mpg, x='horsepower', y='mpg')\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=hp_points['horsepower'],\n",
    "    y=car_model.predict(hp_points),\n",
    "    mode='lines',\n",
    "    name='Predicted MPG using Horsepower'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb17e599",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our regression line doesn't capture the curvature in the relationship between `'horsepower'` and `'mpg'`.\n",
    "\n",
    "Let's look at the residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f2f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mpg.assign(\n",
    "    pred=car_model.predict(mpg[['horsepower']]),\n",
    "    resid=mpg['mpg'] - car_model.predict(mpg[['horsepower']]),\n",
    ")\n",
    "fig = px.scatter(res, x='pred', y='resid')\n",
    "fig.add_hline(0, line_width=3, opacity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe3514",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = car_model.score(mpg[['horsepower']], mpg['mpg'])\n",
    "print(f'Model R¬≤: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff3ec7b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transformations\n",
    "\n",
    "The [Tukey Mosteller Bulge Diagram](https://sites.stat.washington.edu/pds/stat423/Documents/LectureNotes/notes.423.ch4.pdf) helps us pick which transformations to apply to data in order to **linearize** it.\n",
    "\n",
    "<center><img src=\"imgs/bulge.png\" width=25%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3164a12",
   "metadata": {},
   "source": [
    "The bottom-left quadrant appears to match the shape of the scatter plot between `'horsepower'` and `'mpg'` the best ‚Äì let's try taking the `log` of `'horsepower'` ($X$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b90482",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg['log hp'] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b77c02",
   "metadata": {},
   "source": [
    "What does our data look like now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616cc19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(mpg, x='log hp', y='mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9686dfcd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predicting `'mpg'` using `log('horsepower')`\n",
    "\n",
    "Let's fit another linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12526744",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model_log = LinearRegression()\n",
    "car_model_log.fit(mpg[['log hp']], mpg['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e490f0",
   "metadata": {},
   "source": [
    "What do our predictions look like now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1be1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(mpg, x='log hp', y='mpg')\n",
    "log_hp_points = pd.DataFrame({'log hp': [3.7, 5.5]})\n",
    "fig = px.scatter(mpg, x='log hp', y='mpg')\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=log_hp_points['log hp'],\n",
    "    y=car_model_log.predict(log_hp_points),\n",
    "    mode='lines',\n",
    "    name='Predicted MPG using log(Horsepower)'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18fe456",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The fit looks a bit better! How about the $R^2$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d2d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model_log.score(mpg[['log hp']], mpg['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479e1fa5",
   "metadata": {},
   "source": [
    "Also a bit better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a724aa37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What do our predictions look like on the original, non-transformed scatter plot? Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531296eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(mpg, x='horsepower', y='mpg')\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=mpg['horsepower'], \n",
    "        y=car_model_log.intercept_ + car_model_log.coef_[0] * np.log(mpg['horsepower']),  \n",
    "        mode='markers', name='Predicted MPG using log(Horsepower)', marker_color='red'\n",
    "    )\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b93afa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our predictions that used $\\log(\\text{Horsepower})$ as an input don't fall on a straight line. We shouldn't expect them to; the red dots come from:\n",
    "\n",
    "$$\\text{Predicted MPG} = 108.698 - 18.582 \\cdot \\log(\\text{Horsepower})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d99a7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model_log.intercept_, car_model_log.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f7081a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quantitative scaling\n",
    "\n",
    "Until now, feature transformations we've discussed so far have involved converting **categorical** variables into **quantitative** variables. However, our log transformation was an example of transforming a **quantitative** variable into a new **quantitative** variable; this practice is called quantitative scaling.\n",
    "\n",
    "- **Standardization**: $x_i \\rightarrow \\frac{x_i - \\bar{x}}{\\sigma_x}$.\n",
    "- **Linearization via a non-linear transformation**: e.g. $\\text{log}$ and $\\text{sqrt}$. See Lab 8 for more.\n",
    "- **Discretization:** Convert data into percentiles (or more generally, quantiles)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafa5512",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üôãüôãüèΩ‚Äç‚ôÄÔ∏è Questions?\n",
    "\n",
    "https://app.sli.do/event/2LZSnXWNpGPiuVnCZMa5J8\n",
    "\n",
    "<center><img src=\"imgs/slido.svg\" width=\"30%\"></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a95ba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The modeling process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d14ddab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The modeling process\n",
    "\n",
    "<center><img src=\"imgs/image_0.png\" width=\"60%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad26e1d8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Create (engineer) features to best reflect the \"meaning\" behind data.\n",
    "\n",
    "2. Choose a model that is appropriate to capture the relationships between features ($X$) and the target/response ($y$).\n",
    "\n",
    "3. Select a loss function and fit the model (i.e., determine $w^*$).\n",
    "\n",
    "4. Evaluate the model (e.g. using RMSE or $R^2$).\n",
    "\n",
    "**We can perform all of the above directly in `sklearn`!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d7f04d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `preprocessing` and `linear_model`s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc00479",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For the **feature engineering** step of the modeling pipeline, we will use `sklearn`'s [`preprocessing`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) module.\n",
    "\n",
    "<center><img src=\"imgs/feature_part.png\" width=\"30%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9795bf90",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For the **model creation** step of the modeling pipeline, we will use `sklearn`'s [`linear_model`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model) module, as we've already seen. `linear_model.LinearRegression` is an example of an **estimator** class.\n",
    "\n",
    "<center><img src=\"imgs/model_part.png\" width=\"36%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b813b18b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transformers in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41403a4c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transformer classes\n",
    "\n",
    "- **Transformers** take in \"raw\" data and output \"processed\" data. They are used for **creating features**.\n",
    "\n",
    "- The input to a transformer should be a multi-dimensional `numpy` array.\n",
    "    - Inputs can be DataFrames, but `sklearn` only looks at the values (i.e. it calls `to_numpy()` on input DataFrames).\n",
    "\n",
    "- The output of a transformer is a `numpy` array (never a DataFrame or Series).\n",
    "\n",
    "- Transformers, like most relevant features of `sklearn`, are **classes**, not functions, meaning you need to instantiate them and call their methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43f64cd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Case study: Restaurant tips üßë‚Äçüç≥\n",
    "\n",
    "We'll continue working with our trusty `tips` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d159c00f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example transformer: `Binarizer`\n",
    "\n",
    "The `Binarizer` transformer allows us to map a quantitative sequence to a sequence of 1s and 0s, depending on whether values are above or below a threshold.\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize with parameters| `binar = Binarizer(thresh)` | set x=1 if x > thresh, else 0|\n",
    "|Transform data in a dataset | `feat = binar.transform(data)` | Binarize all columns in `data`|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ec5acd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, we need to import the relevant class from `sklearn.preprocessing`. (Tip: import just the relevant classes you need from `sklearn`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95076bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80843c5a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's try binarizing `'total_bill'`. We'll say a \"large\" bill is one that is **strictly** greater than \\$20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f125d13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tips['total_bill'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8186086",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, we initialize a `Binarizer` object with the threshold we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d271a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "611bda9c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then, we call `bi`'s `transform` method and pass it the data we'd like to transform. Note that its input and output are both 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e13219",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_bills = ...\n",
    "transformed_bills[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc577d7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example transformer: `StdScaler`\n",
    "\n",
    "- `StdScaler` **standardizes** data using the mean and standard deviation of the data.\n",
    "\n",
    "$$z(x_i) = \\frac{x_i - \\text{mean of } x}{\\text{SD of } x}$$\n",
    "\n",
    "- Unlike `Binarizer`, `StdScaler` **requires some knowledge (mean and SD) of the dataset before transforming**.\n",
    "\n",
    "- As such, we need to **`fit`** an `StdScaler` transformer before we can use the `transform` method.\n",
    "\n",
    "* Typical usage: fit transformer on a sample, use that fit transformer to transform future data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896bbeaa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example transformer: `StdScaler`\n",
    "\n",
    "It only makes sense to standardize the already-quantitative features of `tips`, so let's select just those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eb2ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_quant = tips[['total_bill', 'size']]\n",
    "tips_quant.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d684be1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's initialize a `StandardScaler` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c8d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5023283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03790dc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that the following **does not work!** The error message is very helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b96342",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "stdscaler.transform(tips_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f6d884",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Instead, we need to first call the `fit` method on `stdscaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91227325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed7f4d3c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, `transform` will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ac743c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "819fc339",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can also access the mean and variance `stdscaler` computed for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfa402a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5125063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89daaa5f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that we can call `transform` on DataFrames other than `tips_quant`. We will do this often ‚Äì fit a transformer on one dataset (training data) and use it to transform other datasets (test data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1abcc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "100744e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üí° Pro-Tip: Using `.fit_transform`\n",
    "\n",
    "The `.fit_transform` method will fit the transformer and then transform the data in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421446fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler.fit_transform(tips_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6481695",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `StdScaler` summary\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize with parameters| `stdscaler = StandardScaler()` | z-score the data (no parameters) |\n",
    "|Fit the transformer| `stdscaler.fit(X)` | Compute the mean and SD of `X`|\n",
    "|Transform data in a dataset | `feat = stdscaler.transform(X_new)` | z-score `X_new` with mean and SD of `X`|\n",
    "|Fit and transform| `stdscaler.fit_transform(X)` | Compute the mean and SD of `X`, then z-score `X`|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468d017d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example transformer: `OneHotEncoder`\n",
    "\n",
    "Let's keep just the categorical columns in `tips`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7f3536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tips_cat = tips[['sex', 'smoker', 'day', 'time']]\n",
    "tips_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af220ea",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Like `StdScaler`, we will need to `fit` our `OneHotEncoder` transformer before it can transform anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f412324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9704c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit(tips_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a93b50",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can look at the unique values (i.e. categories) in each column by using the `categories_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a8a0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162f32b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c5ae7a1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since the resulting matrix is **sparse** ‚Äì most of its elements are 0 ‚Äì `sklearn` uses a more efficient representation than a regular `numpy` array. We can convert to a regular (dense) array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0781a83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f6195a7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice that the column names from `tips_cat` are no longer stored anywhere (remember, `fit` converts the input to a `numpy` array before proceeding).\n",
    "\n",
    "We can use the `get_feature_names_out` method on `ohe` to access the names of the one-hot-encoded columns, though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b192589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ad149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8833fac9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f71de5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"imgs/image_0.png\" width=\"50%\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "So far, we've used transformers for feature engineering and models for prediction. We can combine these steps into a single `Pipeline`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd1ef16",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Pipeline`s in `sklearn`\n",
    "\n",
    "- To instantiate a `Pipeline`, we must provide a list with zero or more transformers followed by a single model.\n",
    "    - All \"steps\" must have `fit` methods, and all but the last must have `transform` methods.\n",
    "    - Template: `pl = Pipeline([feat_trans1, feat_trans2, ..., mdl])`.\n",
    "\n",
    "- Once a `Pipeline` is instantiated, you can fit **all** steps (transformers and model) using a single call to the `fit` method.\n",
    "```py\n",
    "pl.fit(X, y)\n",
    "```\n",
    "\n",
    "- To make predictions using **raw, untransformed data**, use `pl.predict`.\n",
    "\n",
    "- The actual list we provide `Pipeline` with must be a list of **tuples**, where\n",
    "    - The first element is a \"name\" (that we choose) for the step.\n",
    "    - The second element is a transformer or estimator instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86669e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Our first `Pipeline`\n",
    "\n",
    "Let's build a `Pipeline` that:\n",
    "- One hot encodes the categorical features in `tips`.\n",
    "- Fits a regression model on the one hot encoded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03859c62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tips_cat = tips[['sex', 'smoker', 'day', 'time']]\n",
    "tips_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7cf9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49f763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pl = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56ef92c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now that `pl` is instantiated, we `fit` it the same way we would fit the individual steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def920bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b902c9f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, to make predictions using **raw data**, all we need to do is use `pl.predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628bc44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d8518b9",
   "metadata": {},
   "source": [
    "`pl` performs **both** feature transformation and prediction with just a single call to `predict`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea45098",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can access individual \"steps\" of a `Pipeline` through the `named_steps` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93061e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee75ef28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70c7b1ba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`pl` also has a `score` method, the same way a fit `LinearRegression` instance does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c6673b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b4fc2ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More sophisticated `Pipeline`s\n",
    "\n",
    "- In the previous example, we one hot encoded every input column. **What if we want to perform different transformations on different columns?**\n",
    "\n",
    "- **Solution:** Use a `ColumnTransformer`.\n",
    "    - Instantiate a `ColumnTransformer` using a list of tuples, where:\n",
    "        - The first element is a \"name\" we choose for the transformer.\n",
    "        - The second element is a transformer instance (e.g. `OneHotEncoder()`).\n",
    "        - The third element is a **list of relevant column names**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e477c359",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Planning our first `ColumnTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd28cf",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0ecc2b",
   "metadata": {},
   "source": [
    "Let's perform different transformations on the quantitative and categorical features of `tips` (note that we are not transforming `'tip'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf2ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_features = tips.drop('tip', axis=1)\n",
    "tips_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b564152",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We will leave the `'total_bill'` column untouched.\n",
    "\n",
    "- To the `'size'` column, we will apply the `Binarizer` transformer with a threshold of 2 (big tables vs. small tables).\n",
    "\n",
    "- To the categorical columns, we will apply the `OneHotEncoder` transformer.\n",
    "\n",
    "- In essence, we will create a transformer that reproduces the following DataFrame:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>size</th>\n",
    "      <th>x0_Female</th>\n",
    "      <th>x0_Male</th>\n",
    "      <th>x1_No</th>\n",
    "      <th>x1_Yes</th>\n",
    "      <th>x2_Fri</th>\n",
    "      <th>x2_Sat</th>\n",
    "      <th>x2_Sun</th>\n",
    "      <th>x2_Thur</th>\n",
    "      <th>x3_Dinner</th>\n",
    "      <th>x3_Lunch</th>\n",
    "      <th>total_bill</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>16.99</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>1</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>10.34</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>1</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>21.01</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>23.68</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>1</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>24.59</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89393533",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building a `Pipeline` using a `ColumnTransformer`\n",
    "\n",
    "Let's start by creating our `ColumnTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e5854",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ...\n",
    "    ],\n",
    "    remainder='passthrough' # Specify what to do with all other columns ('total_bill' here) ‚Äì drop or passthrough.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06f5569",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, let's create a `Pipeline` using `preproc` as a transformer, and `fit` it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aee4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ...\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc44a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad5db465",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Prediction is as easy as calling `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3f595",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tips_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we fit the Pipeline using tips_features, not tips_features.head()!\n",
    "pl.predict(tips_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b1a71",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: `FunctionTransformer`\n",
    "\n",
    "A transformer you'll often use as part of a `ColumnTransformer` is the `FunctionTransformer`, which enables you to use your own functions on entire columns. Think of it as the `sklearn` equivalent of `apply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5dbb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede5821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f6f679d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: `Pipeline`s\n",
    "\n",
    "- `Pipeline`s are powerful because they allow you to perform feature engineering and training/prediction all through a single object.\n",
    "- As we'll see next time, they also allow us to easily compare models against each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5884b7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üôãüôãüèΩ‚Äç‚ôÄÔ∏è Questions?\n",
    "\n",
    "https://app.sli.do/event/2LZSnXWNpGPiuVnCZMa5J8\n",
    "\n",
    "<center><img src=\"imgs/slido.svg\" width=\"30%\"></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f29f107",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179b0dd3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Motivation\n",
    "\n",
    "- You and Billy are studying for an upcoming exam. You both decide to test your understanding by taking a **practice exam**.\n",
    "    - Your logic: If you do well on the practice exam, you should do well on the real exam.\n",
    "\n",
    "- You each take the practice exam once and look at the solutions afterwards.\n",
    "\n",
    "- **Your strategy**: Memorize the answers to all practice exam questions, e.g. \"Question 1: A; Question 2: C; Question 3: A.\"\n",
    "\n",
    "- **Billy's strategy**: Learn high-level concepts from the solutions, e.g. \"data are NMAR if the likelihood of missingness depends on the missing values themselves.\"\n",
    "\n",
    "- Who will do better on the **practice exam**? Who will probably do better on the **real exam**? üßê"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32bb5b3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluating the quality of a model\n",
    "\n",
    "- So far, we've computed the RMSE (and $R^2$) of our fit regression models on the **data that we used to fit them**, i.e. the **training data**.\n",
    "\n",
    "- We've said that Model A is **better** than Model B if Model A's RMSE is **lower** than Model B's RMSE.\n",
    "    - Remember, our **training data** is a sample from the data generating process.\n",
    "    - Just because a model fits the training data well doesn't mean it will **generalize** and work well on **similar, unseen samples**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7ddd1f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Overfitting and underfitting\n",
    "\n",
    "Let's collect two samples $\\{(x_i, y_i)\\}$ from the same **data generating process**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39134087",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(23) # For reproducibility.\n",
    "\n",
    "def sample_dgp(n=100):\n",
    "    x = np.linspace(-2, 3, n)\n",
    "    y = x ** 3 + (np.random.normal(0, 3, size=n))\n",
    "    return pd.DataFrame({'x': x, 'y': y})\n",
    "\n",
    "sample_1 = sample_dgp()\n",
    "sample_2 = sample_dgp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add47e11",
   "metadata": {},
   "source": [
    "For now, let's just look at Sample 1. The relationship between $x$ and $y$ is roughly **cubic**; that is, $y \\approx x^3$ (remember, in reality, you won't get to see the DGP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d8dc21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px.scatter(sample_1, x='x', y='y', title='Sample 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa10ff0a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Polynomial regression\n",
    "\n",
    "Let's fit three **polynomial** models on Sample 1:\n",
    "- Degree 1.\n",
    "- Degree 3.\n",
    "- Degree 25.\n",
    "\n",
    "The `PolynomialFeatures` transformer will be helpful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20eadf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13f6b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = PolynomialFeatures(3)\n",
    "d2.fit_transform(np.array([1, 2, 3, 4, -2]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8771f73d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Below, we look at our three models' predictions on Sample 1 (which they were trained on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f8a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the definition of train_and_plot in util.py if you're curious as to how the plotting works.\n",
    "import lec14_util as util\n",
    "fig = util.train_and_plot(train_sample=sample_1, test_sample=sample_1, degs=[1, 3, 25])\n",
    "fig.update_layout(title='Trained on Sample 1, Performance on Sample 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a98fb8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The degree 25 polynomial has the lowest RMSE on Sample 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d242734c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do the same fit polynomials look on Sample 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f83da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = util.train_and_plot(train_sample=sample_1, test_sample=sample_2, degs=[1, 3, 25])\n",
    "fig.update_layout(title='Trained on Sample 1, Performance on Sample 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3527e712",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The degree 3 polynomial has the lowest RMSE on Sample 2. \n",
    "\n",
    "\n",
    "- Note that **we didn't get to see Sample 2 when fitting our models**! \n",
    "\n",
    "\n",
    "- As such, it seems that the degree 3 polynomial **generalizes better** to unseen data than the degree 25 polynomial does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793cabe0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What if we fit a degree 1, degree 3, and degree 25 polynomial **on Sample 2** as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb427170",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.plot_multiple_models(sample_1, sample_2, degs=[1, 3, 25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab5bd0f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Key idea**: Degree 25 polynomials seem to **vary more when trained on different samples** than degree 3 and 1 polynomials do.\n",
    "\n",
    "- Next time: We'll investigate this phenomenon in-depth, and introduce techniques for choosing the best model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
