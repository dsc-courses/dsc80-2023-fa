{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c8a44b8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from dsc80_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21df0f00",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import lec08_utils as util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e66d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 8 ‚Äì Imputation\n",
    "\n",
    "## DSC 80, Fall 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22824200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üì£ Announcements üì£\n",
    "\n",
    "- Good job on Project 2 checkpoint!\n",
    "- Lab 4 due Monday.\n",
    "- Midterm exam will happen next week on Thurs Nov 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbabdc2d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üìù Midterm Exam\n",
    "\n",
    "- Thurs, Nov 2 from 3:30-4:50pm in WLH 2005.\n",
    "- Pen and paper only. No calculators, phones, or watches allowed.\n",
    "- You are allowed to bring one double-sided 8.5\" x 11\" sheet of handwritten notes.\n",
    "    - No reference sheet given, unlike DSC 10!\n",
    "- We will display clarifications and the time remaining during the exam.\n",
    "- Covers Lectures 1-8, Labs 1-4, and Projects 1-2.\n",
    "- To review problems from old exams, go to [practice.dsc80.com](https://practice.dsc80.com).\n",
    "    - Also look at the [Resources](https://dsc80.com/resources) tab on the course website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd851d5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üìÜ Agenda\n",
    "\n",
    "- [ ] Review of missingness mechanisms\n",
    "- [ ] Deciding between MCAR and MAR using a hypothesis test\n",
    "    - [ ] The Kolmogorov-Smirnov test statistic\n",
    "- [ ] Mean Imputation\n",
    "- [ ] Probabilistic Imputation\n",
    "- [ ] Multiple Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1321c1b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review: Missingness mechanisms\n",
    "\n",
    "A good strategy is to assess missingness in the following order.\n",
    "\n",
    "<center><b>Missing by design (MD)</b></center>\n",
    "<center><i>Can I determine the missing value exactly by looking at the other columns?</i> ü§î</center>\n",
    "<center> ‚¨áÔ∏è </center>\n",
    "\n",
    "<center><b>Not missing at random (NMAR)</b></center>\n",
    "<center><i>Is there a good reason why the missingness depends on the values themselves?</i> ü§î</center>\n",
    "<center> ‚¨áÔ∏è </center>\n",
    "\n",
    "<center><b>Missing at random (MAR)</b></center>\n",
    "<center><i>Do other columns tell me anything about the likelihood that a value is missing? </i>ü§î</center>\n",
    "<center> ‚¨áÔ∏è </center>\n",
    "\n",
    "<center><b>Missing completely at random (MCAR)</b></center>\n",
    "<center><i>The missingness must not depend on other columns or the values themselves. </i>üòÑ</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01815d59",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review: Assessing missingness through data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d20bd5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Heights\n",
    "\n",
    "- Let's load in Galton's dataset containing the heights of adult children and their parents (which you may have seen in DSC 10).\n",
    "- The dataset does not contain any missing values ‚Äì we will **artifically introduce missing values** such that the values are MCAR, for illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02a2bd7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "heights = pd.read_csv('data/midparent.csv')\n",
    "heights = heights.rename(columns={'childHeight': 'child'})\n",
    "heights = heights[['father', 'mother', 'gender', 'child']]\n",
    "heights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaab080",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simulating MCAR data\n",
    "\n",
    "- We will make `'child'` MCAR by taking a random subset of `heights` and setting the corresponding `'child'` heights to `np.NaN`.\n",
    "- This is equivalent to flipping a (biased) coin for each row. \n",
    "    - If heads, we delete the `'child'` height.\n",
    "- **You will not do this in practice!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570e74ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # So that we get the same results each time (for lecture).\n",
    "\n",
    "heights_mcar = heights.copy()\n",
    "idx = heights_mcar.sample(frac=0.3).index\n",
    "heights_mcar.loc[idx, 'child'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mcar.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fec198",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mcar.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059f4943",
   "metadata": {},
   "source": [
    "Aside: Why is the value for `'child'` in the above Series not exactly 0.3?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d3096b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Verifying that child heights are MCAR in `heights_mcar`\n",
    "\n",
    "- Each row of `heights_mcar` belongs to one of two **groups**:\n",
    "    - Group 1: `'child'` is missing.\n",
    "    - Group 2: `'child'` is not missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5566d35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mcar['child_missing'] = heights_mcar['child'].isna()\n",
    "heights_mcar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f46bb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We need to look at the distributions of every other column ‚Äì `'gender'`, `'mother'`, and `'father'` ‚Äì separately for these two groups, and check to see if they are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903253af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing null and non-null `'child'` distributions for `'gender'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd2000",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dist = (\n",
    "    heights_mcar\n",
    "    .assign(child_missing=heights_mcar['child'].isna())\n",
    "    .pivot_table(index='gender', columns='child_missing', aggfunc='size')\n",
    ")\n",
    "\n",
    "# Added just to make the resulting pivot table easier to read.\n",
    "gender_dist.columns = ['child_missing = False', 'child_missing = True']\n",
    "\n",
    "gender_dist = gender_dist / gender_dist.sum()\n",
    "gender_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfed2244",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that here, each column is a separate distribution that adds to 1.\n",
    "\n",
    "- The two columns look similar, which is evidence that `'child'`'s missingness does not depend on `'gender'`.\n",
    "    - Knowing that the child is `'female'` doesn't make it any more or less likely that their height is missing than knowing if the child is `'male'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc69137c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing null and non-null `'child'` distributions for `'gender'`\n",
    "\n",
    "- In the previous slide, we saw that the distribution of `'gender'` is similar whether or not `'child'` is missing.\n",
    "\n",
    "- To make precise what we mean by \"similar\", we can run a permutation test. We are comparing two distributions:\n",
    "    1. The distribution of `'gender'` when `'child'` is missing.\n",
    "    2. The distribution of `'gender'` when `'child'` is not missing.\n",
    "\n",
    "- What test statistic do we use to compare categorical distributions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e7788",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "gender_dist.plot(kind='barh', title='Gender by Missingness of Child Height', barmode='group')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34398a8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To measure the \"distance\" between two categorical distributions, we use the **total variation distance**.\n",
    "\n",
    "Note that  with only two categories, the TVD is the same as the absolute difference in proportions for either category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a12c13e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simulation\n",
    "\n",
    "The code to run our simulation largely looks the same as in previous permutation tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57194779",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n_repetitions = 500\n",
    "shuffled = heights_mcar.copy()\n",
    "\n",
    "tvds = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # Shuffling genders. \n",
    "    # Note that we are assigning back to the same DataFrame for performance reasons; \n",
    "    # see https://dsc80.com/resources/lectures/lec07/lec07-fast-permutation-tests.html\n",
    "    shuffled['gender'] = np.random.permutation(shuffled['gender'])\n",
    "    \n",
    "    # Computing and storing the TVD.\n",
    "    pivoted = (\n",
    "        shuffled\n",
    "        .pivot_table(index='gender', columns='child_missing', aggfunc='size')\n",
    "        .apply(lambda x: x / x.sum())\n",
    "    )\n",
    "    \n",
    "    tvd = pivoted.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "    tvds.append(tvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f952a343",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "observed_tvd = gender_dist.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "observed_tvd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae18299",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fc2b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16bbf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(pd.DataFrame(tvds), x=0, nbins=50, histnorm='probability', \n",
    "                   title='Empirical Distribution of the TVD')\n",
    "fig.add_vline(x=observed_tvd, line_color='red', line_width=2, opacity=1)\n",
    "fig.add_annotation(text=f'<span style=\"color:red\">Observed TVD = {round(observed_tvd, 2)}</span>',\n",
    "                   x=4 * observed_tvd, showarrow=False, y=0.16)\n",
    "fig.update_layout(yaxis_range=[0, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce201999",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(tvds) >= observed_tvd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2af6c73",
   "metadata": {},
   "source": [
    "- We fail to reject the null.\n",
    "- Recall, the null stated that the distribution of `'gender'` when `'child'` is missing is the same as the distribution of `'gender'` when `'child'` is not missing.\n",
    "- Hence, we conclude that the missingness in the `'child'` column is not dependent on `'gender'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222acc46",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing null and non-null `'child'` distributions for `'father'`\n",
    "\n",
    "- We again must compare two distributions:\n",
    "    1. The distribution of `'father'` when `'child'` is missing.\n",
    "    2. The distribution of `'father'` when `'child'` is not missing.\n",
    "\n",
    "- If the distributions are similar, we conclude that the missingness of `'child'` is not dependent on the height of the `'father'`.\n",
    "\n",
    "- We can again use a permutation test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78287427",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "px.histogram(heights_mcar, x='father', color='child_missing', histnorm='probability', marginal='box',\n",
    "             title=\"Father's Height by Missingness of Child Height\", barmode='overlay', opacity=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a341fe2b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can visualize numerical distributions with histograms, or with **kernel density estimates**. (See the definition of `create_kde_plotly` at the top of the notebook if you're curious as to how these are created.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d44c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.create_kde_plotly(heights_mcar, 'child_missing', True, False, 'father', \n",
    "                       \"Father's Height by Missingness of Child Height\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4938cd1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Concluding that `'child'` is MCAR\n",
    "\n",
    "- We need to run three permutation tests ‚Äì one for each column in `heights_mcar` other than `'child'`.\n",
    "\n",
    "- For every other column, if we **fail to reject the null** that the distribution of the column when `'child'` is missing is the same as the distribution of the column when `'child'` is not missing, then we can conclude `'child'` is MCAR.\n",
    "    - In such a case, its missingness is not tied to any other columns.\n",
    "    - For instance, children with shorter fathers are not any more likely to have missing heights than children with taller fathers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8086a8c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simulating MAR data\n",
    "\n",
    "Now, we will make `'child'` heights MAR by deleting `'child'` heights according to a random procedure that **depends on other columns**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98aa834",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # So that we get the same results each time (for lecture).\n",
    "\n",
    "def make_missing(r):\n",
    "    rand = np.random.uniform() # Random real number between 0 and 1.\n",
    "    if r['father'] > 72 and rand < 0.5:\n",
    "        return np.NaN\n",
    "    elif r['gender'] == 'female' and rand < 0.3:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return r['child']\n",
    "    \n",
    "heights_mar = heights.copy()\n",
    "heights_mar['child'] = heights_mar.apply(make_missing, axis=1)\n",
    "heights_mar['child_missing'] = heights_mar['child'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a1d00c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heights_mar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664dc107",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing null and non-null `'child'` distributions for `'gender'`, again\n",
    "\n",
    "This time, the distribution of `'gender'` in the two groups is very different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232969dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dist = (\n",
    "    heights_mar\n",
    "    .assign(child_missing=heights_mar['child'].isna())\n",
    "    .pivot_table(index='gender', columns='child_missing', aggfunc='size')\n",
    ")\n",
    "\n",
    "# Added just to make the resulting pivot table easier to read.\n",
    "gender_dist.columns = ['child_missing = False', 'child_missing = True']\n",
    "\n",
    "gender_dist = gender_dist / gender_dist.sum()\n",
    "gender_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc305106",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "gender_dist.plot(kind='barh', title='Gender by Missingness of Child Height', barmode='group')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee33699c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing null and non-null `'child'` distributions for `'father'`, again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbdf543",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "util.create_kde_plotly(heights_mar, 'child_missing', True, False, 'father', \n",
    "                       \"Father's Height by Missingness of Child Height\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c358c0b3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The above two distributions look quite different.\n",
    "    - This is because we artificially created missingness in the dataset in a way that depended on `'father'` and `'gender'`.\n",
    "\n",
    "- However, their difference in means is small:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc36c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mar.groupby('child_missing')['father'].mean().diff().iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50521ade",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we ran a permutation test with the difference in means as our test statistic, we would fail to reject the null.\n",
    "    - **Using just the difference in means, it is hard to tell these two distributions apart.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e21dcd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Kolmogorov-Smirnov test statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5644b01d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: Permutation tests\n",
    "\n",
    "- Permutation tests help decide whether **two samples look like they were drawn from the same population distribution**.\n",
    "- In a permutation test, we simulate data under the null by **shuffling** either group labels or numerical features.\n",
    "    - In effect, this **randomly assigns individuals to groups**.\n",
    "- If the two distributions are **quantitative (numerical)**, we've used as our test statistic the **difference in group means or medians**.\n",
    "- If the two distributions are **qualitative (categorical)**, we've used as our test statistic the **total variation distance (TVD)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee559907",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Difference in means\n",
    "\n",
    "The difference in means works well in some cases. Let's look at one such case.\n",
    "\n",
    "Below, we artificially generate two numerical datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e01b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # So that we get the same results each time (for lecture).\n",
    "\n",
    "N = 1000 # Number of samples for each distribution.\n",
    "\n",
    "# Distribution 'A'.\n",
    "distr1 = pd.Series(np.random.normal(0, 1, size=N//2))\n",
    "\n",
    "# Distribution 'B'.\n",
    "distr2 = pd.Series(np.random.normal(3, 1, size=N//2))\n",
    "\n",
    "data = pd.concat([distr1, distr2], axis=1, keys=['A', 'B']).unstack().reset_index().drop('level_1', axis=1)\n",
    "data = data.rename(columns={'level_0': 'group', 0: 'data'})\n",
    "\n",
    "meanA, meanB = data.groupby('group')['data'].mean().round(7).tolist()\n",
    "util.create_kde_plotly(data, 'group', 'A', 'B', 'data', f'mean of A: {meanA}<br>mean of B: {meanB}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab6f7e0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion Question\n",
    "\n",
    "- So far, we have used the difference in means as our test statistic in quantitative permutation tests.\n",
    "- We've concluded that **two distributions were likely different if their means were different**.\n",
    "- Can you think of two **different** distributions that have the same mean? ü§î"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ad61ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Different distributions with the same mean\n",
    "\n",
    "Let's generate two distributions that look very different but have the same mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a76426",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # So that we get the same results each time (for lecture).\n",
    "\n",
    "N = 1000 # Number of samples for each distribution.\n",
    "\n",
    "# Distribution 'A'.\n",
    "a = pd.Series(np.random.normal(0, 1, size=N//2))\n",
    "b = pd.Series(np.random.normal(4, 1, size=N//2))\n",
    "distr1 = pd.concat([a,b], ignore_index=True)\n",
    "\n",
    "# Distribution 'B'.\n",
    "distr2 = pd.Series(np.random.normal(distr1.mean(), distr1.std(), size=N))\n",
    "\n",
    "data = pd.concat([distr1, distr2], axis=1, keys=['A', 'B']).unstack().reset_index().drop('level_1', axis=1)\n",
    "data = data.rename(columns={'level_0': 'group', 0: 'data'})\n",
    "\n",
    "meanA, meanB = data.groupby('group')['data'].mean().round(7).tolist()\n",
    "util.create_kde_plotly(data, 'group', 'A', 'B', 'data', f'mean of A: {meanA}<br>mean of B: {meanB}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7ce709",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this case, if we use the difference in means as our test statistic in a permutation test, we will fail to reject the null that the two distributions are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f99b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 500\n",
    "shuffled = data.copy()\n",
    "\n",
    "diff_means = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # Shuffling the values, while keeping the group labels in place.\n",
    "    shuffled['data'] = np.random.permutation(shuffled['data'])\n",
    "    \n",
    "    # Computing and storing the absolute difference in means.\n",
    "    diff_mean = shuffled.groupby('group')['data'].mean().diff().abs().iloc[-1]\n",
    "    diff_means.append(diff_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07361789",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "observed_diff = data.groupby('group')['data'].mean().diff().abs().iloc[-1]\n",
    "fig = px.histogram(pd.DataFrame(diff_means), x=0, nbins=50, histnorm='probability', \n",
    "                   title='Empirical Distribution of the Absolute Difference in Means')\n",
    "fig.add_vline(x=observed_diff, line_color='red', line_width=1, opacity=1)\n",
    "fig.add_annotation(text=f'<span style=\"color:red\">Observed Absolute Difference in Means = {round(observed_diff, 2)}</span>',\n",
    "                   x=1.45 * observed_diff, showarrow=False, y=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1398efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The computed p-value is fairly large.\n",
    "np.mean(np.array(diff_means) >= observed_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd283870",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Telling quantitative distributions apart\n",
    "\n",
    "- The difference in means only works as a test statistic in permutation tests **if the two distributions have similar shapes**.\n",
    "    - It tests to see if one is a shifted version of the other.\n",
    "\n",
    "- We need a better test statistic to differentiate between quantitative distributions with different shapes.\n",
    "\n",
    "- In other words, we need a **distance** metric between quantitative distributions.\n",
    "    - The TVD is a distance metric between categorical distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcc676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.create_kde_plotly(data, 'group', 'A', 'B', 'data', f'mean of A: {meanA}<br>mean of B: {meanB}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c37a95",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Kolmogorov-Smirnov test statistic\n",
    "\n",
    "- The K-S test statistic measures the similarity between two distributions.\n",
    "- It is defined in terms of the **cumulative distribution function (CDF)** of a given distribution.\n",
    "    - If $f(x)$ is a distribution, then the CDF $F(x)$ is the proportion of values in distribution $f$ that are less than or equal to $x$.\n",
    "- The K-S statistic is roughly defined as the **largest difference between two CDFs**.\n",
    "<center><img src=./imgs/KS2_Example.png width=50%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2587e2a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: cumulative distribution functions\n",
    "\n",
    "Let's look at the CDFs of our two synthetic distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d6bfa0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Think about what this function is doing!\n",
    "def create_cdf(group):\n",
    "    return data.loc[data['group'] == group, 'data'].value_counts(normalize=True).sort_index().cumsum()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=create_cdf('A').index, y=create_cdf('A'), name='CDF of A')\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=create_cdf('B').index, y=create_cdf('B'), name='CDF of B')\n",
    ")\n",
    "\n",
    "fig.update_layout(title='CDFs of A and B')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbc18b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The K-S statistic in Python\n",
    "\n",
    "Fortunately, **we don't need to calculate the K-S statistic ourselves**! Python can do it for us (and you can use this pre-built version in all assignments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4469a01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb045882",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86095baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_ks = ...\n",
    "observed_ks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0d59ea",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We don't know if this number is big or small. We need to run a permutation test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 500\n",
    "shuffled = data.copy()\n",
    "\n",
    "ks_stats = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # Shuffling the data.\n",
    "    shuffled['data'] = np.random.permutation(shuffled['data'])\n",
    "    \n",
    "    # Computing and storing the K-S statistic.\n",
    "    groups = ...\n",
    "    ks_stat = ...\n",
    "    ks_stats.append(ks_stat)\n",
    "    \n",
    "ks_stats[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8fd255",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(pd.DataFrame(ks_stats), x=0, nbins=50, histnorm='probability', \n",
    "                   title='Empirical Distribution of the K-S Statistic')\n",
    "fig.add_vline(x=observed_ks, line_color='red', line_width=1, opacity=1)\n",
    "fig.add_annotation(text=f'<span style=\"color:red\">Observed KS = {round(observed_ks, 2)}</span>',\n",
    "                   x=0.8 * observed_ks, showarrow=False, y=0.16)\n",
    "\n",
    "fig.update_layout(xaxis_range=[0, 0.2])\n",
    "fig.update_layout(yaxis_range=[0, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfbec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(ks_stats) >= observed_ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15934f5",
   "metadata": {},
   "source": [
    "We were able to differentiate between the two distributions using the K-S test statistic!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49301fbb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `ks_2samp`\n",
    "\n",
    "* `scipy.stats.ks_2samp` actually returns **both** the statistic **and** a p-value.\n",
    "* The p-value is calculated using the permutation test we just performed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7360aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(data.loc[data['group'] == 'A', 'data'], data.loc[data['group'] == 'B', 'data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6db1889",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Difference in means vs. K-S statistic\n",
    "\n",
    "- The K-S statistic measures the difference between two numeric distributions.\n",
    "\n",
    "- It **does not** quantify if one is larger than the other on average, so there are times we still need to use the difference in means.\n",
    "\n",
    "- Strategy: Always plot the two distributions you are comparing.\n",
    "    - If the distributions have similar shapes but are centered in different places, use the difference in means (or absolute difference in means).\n",
    "    - If your alternative hypothesis involves a \"direction\" (i.e. smoking weights were are on average than non-smoking weights), use the difference in means.\n",
    "    - If the distributions have different shapes and your alternative hypothesis is simply that the two distributions are different, use the K-S statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057756ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Back to our Example: Missingness of `'child'` heights on `'father'`'s heights (MAR)\n",
    "\n",
    "- **Question:** Is the missingness of `'child'` heights dependent on the `'father'` column?\n",
    "\n",
    "- We will follow the same procedure as before. The only difference is that the missing values in our simulated data are MAR dependent on `'father'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our MAR data\n",
    "heights_mar.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a609393",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Missingness of `'child'` heights on `'father'`'s heights (MAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27634d9c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "heights_mar['child_missing'] = heights_mar['child'].isna()\n",
    "util.create_kde_plotly(heights_mar[['child_missing', 'father']], 'child_missing', True, False, 'father',\n",
    "                       \"Father's Height by Missingness of Child Height (MAR example)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc833c45",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The above picture shows us that missing `'child'` heights tend to come from taller `'father'`s heights.\n",
    "\n",
    "- To determine whether the two distributions are significantly different, we must use a permutation test. This time, the difference in means is not a good choice, since the centers are similar but the shapes are different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b48cae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion Question\n",
    "\n",
    "In this MAR example, if we were to take the mean of the `'child'` column that contains missing values, is the result likely to:\n",
    "\n",
    "1. Overestimate the true mean?\n",
    "2. Underestimate the true mean?\n",
    "3. Be accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.create_kde_plotly(heights_mar[['child_missing', 'father']], 'child_missing', True, False, 'father',\n",
    "                       \"Father's Height by Missingness of Child Height (MAR example)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c7fd9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Performing the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b68840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8d2c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bcc41c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**The p-value is very small, so we conclude that the child height is MAR, conditional on the father's height.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74869575",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44562e8d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What do we do with missing data?\n",
    "\n",
    "- Suppose we are interested in a dataset $Y$. \n",
    "- We get to **observe** $Y_{obs}$, while the rest of the dataset, $Y_{mis}$, is **missing**.\n",
    "- Issue: $Y_{obs}$ may look quite different than $Y$.\n",
    "    - The mean and other measures of central tendency may be different.\n",
    "    - The variance may be different.\n",
    "    - The correlations between variables may be different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e859698f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solution 1: Dropping missing values\n",
    "\n",
    "- If the data are MCAR (missing completely at random), then dropping the missing values entirely doesn't significantly change the data.\n",
    "    - For instance, the mean of the dataset post-dropping is an unbiased estimate of the true mean.\n",
    "    - This is because MCAR data is a **random sample** of the full dataset.\n",
    "    - From DSC 10, we know that random samples tend to resemble the larger populations they are drawn from.\n",
    "\n",
    "- **If the data are not MCAR, then dropping the missing values will introduce bias.**\n",
    "    - MCAR is rare!\n",
    "    - For instance, suppose we asked people \"How much do you give to charity?\" People who give little are less likely to respond, so the average response is **biased high**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f898576",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Listwise deletion\n",
    "\n",
    "- _Listwise deletion_ is the act of dropping entire rows that contain missing values.\n",
    "- Issue: This can delete perfectly good data in other columns for a given row.\n",
    "    - Improvement: Drop missing data only when working with the column that contains missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6716964",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To illustrate, let's generate two datasets with missing `'child'` heights ‚Äì one in which the heights are MCAR, and one in which they are MAR dependent on `'gender'` (**not** `'father'`, as in our previous example).\n",
    "\n",
    "**In practice, you'll have to run permutation tests to determine the likely missingness mechanism first!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926585b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # So that we get the same results each time (for lecture).\n",
    "heights_mcar = util.make_mcar(heights, 'child', pct=0.5)\n",
    "heights_mar = util.make_mar_on_cat(heights, 'child', 'gender', pct=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd708948",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Listwise deletion\n",
    "\n",
    "Below, we compute the means and standard deviations of the `'child'` column in all three datasets. Remember, `.mean()` and `.std()` ignore missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb177bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.multiple_describe({\n",
    "    'Original': heights,\n",
    "    'MCAR': heights_mcar,\n",
    "    'MAR': heights_mar\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c74b86",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Observations:\n",
    "\n",
    "- The `'child'` mean (and SD) in the MCAR dataset is very close to the true `'child'` mean (and SD).\n",
    "\n",
    "- The `'child'` mean in the MAR dataset is biased **high**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf5f05",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solution 2: Imputation\n",
    "\n",
    "**Imputation** is the act of filling in missing data with plausable values. Ideally, imputation:\n",
    "\n",
    "* is quick and easy to do.\n",
    "* shouldn't introduce bias into the dataset.\n",
    "\n",
    "These are hard to do at the same time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf869e5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Kinds of imputation\n",
    "\n",
    "- There are three main types of imputation, two of which we will focus on today:\n",
    "\n",
    "    - **Imputation with a single value: mean, median, mode.**\n",
    "    - Imputation with a single value, using a model: regression, kNN.\n",
    "    - **Probabilistic imputation by drawing from a distribution.**\n",
    "\n",
    "- Each has upsides and downsides, and **each works differently with different types of missingness**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e3bca0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mean imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa679e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mean imputation\n",
    "\n",
    "- Mean imputation is the act of filling in missing values in a column with the mean of the observed values in that column.\n",
    "- This strategy:\n",
    "    - üëç Preserves the mean of the observed data, for all types of missingness.\n",
    "    - üëé Decreases the variance of the data, for all types of missingness.\n",
    "    - üëé Creates a biased estimate of the true mean when the data are not MCAR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4158145a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Mean imputation in the MCAR `heights` dataset\n",
    "\n",
    "Let's look at two distributions:\n",
    "- The distribution of the `'child'` column in `heights`, where we have all the data.\n",
    "- The distribution of the `'child'` column in `heights_mcar`, where some values are MCAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c2fe5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Look in util.py to see how multiple_kdes is defined.\n",
    "util.multiple_kdes({'Original': heights, 'MCAR, Unfilled': heights_mcar})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37ed603",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Since the `'child'` heights are MCAR, the <span style='color:rgb(217,95,2)'><b> orange distribution, in which some values are missing</b></span>, has roughly the same shape as the <span style='color:rgb(27,158,119)'><b>turquoise distribution, which has no missing values</b></span>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3c0acd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mean imputation of MCAR data\n",
    "\n",
    "Let's fill in missing values in `heights_mcar['child']` with the mean of the observed `'child'` heights in `heights_mcar['child']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737b8ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mcar['child'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daeccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mcar_mfilled = ...\n",
    "heights_mcar_mfilled['child'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda6c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = {'Original': heights, 'MCAR, Unfilled': heights_mcar, 'MCAR, Mean Imputed': heights_mcar_mfilled}\n",
    "util.multiple_describe(df_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7284d51",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Observations:\n",
    "\n",
    "- The mean of the imputed dataset is the same as the mean of the subset of heights that aren't missing (which is close to the true mean).\n",
    "\n",
    "- The standard deviation of the imputed dataset smaller than that of the other two datasets. **Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7958e5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mean imputation of MCAR data\n",
    "\n",
    "Let's visualize all three distributions: the original, the MCAR heights with missing values, and the mean-imputed MCAR heights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568711a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "util.multiple_kdes(df_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580208d6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Takeaway**: When data are MCAR and you impute with the mean:\n",
    "- The mean of the imputed dataset is an **unbiased estimator** of the true mean.\n",
    "- The variance of the imputed dataset is smaller than the variance of the full dataset.\n",
    "    - Mean imputation tricks you into thinking your data are more reliable than they are!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecb4ea3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Mean imputation in the MAR `heights` dataset\n",
    "\n",
    "- When data are MAR, mean imputation leads to biased estimates of the mean across groups.\n",
    "\n",
    "- The bias may be different in different groups.\n",
    "    - For example: If the missingness depends on gender, then different genders will have differently-biased means.\n",
    "    - The overall mean will be biased towards one group.\n",
    "\n",
    "- Again, let's look at two distributions:\n",
    "    - The distribution of the `'child'` column in `heights`, where we have all the data.\n",
    "    - The distribution of the `'child'` column in `heights_mar`, where some values are MAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51a8917",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.multiple_kdes({'Original': heights, 'MAR, Unfilled': heights_mar})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73f57b5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The distributions are not very similar!\n",
    "\n",
    "Remember that in reality, you won't get to see the <span style='color:rgb(27,158,119)'><b>turquoise distribution, which has no missing values</b></span> ‚Äì instead, you'll try to recreate it, using your sample with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3fe43b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mean imputation of MAR data\n",
    "\n",
    "Let's fill in missing values in `heights_mar['child']` with the mean of the observed `'child'` heights in `heights_mar['child']` and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd6bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mar['child'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11675c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mar_mfilled = ...\n",
    "heights_mar_mfilled['child'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d9fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = {'Original': heights, 'MAR, Unfilled': heights_mar, 'MAR, Mean Imputed': heights_mar_mfilled}\n",
    "util.multiple_describe(df_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddab62dc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that the latter two means are biased **high**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142a92a0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mean imputation of MAR data\n",
    "\n",
    "Let's visualize all three distributions: the original, the MAR heights with missing values, and the mean-imputed MAR heights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8990427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.multiple_kdes(df_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c41cddd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since the sample with MAR values was already biased high, mean imputation kept the sample biased ‚Äì it did not bring the data **closer to the data generating process**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ab1f17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With our single mean imputation strategy, the resulting female mean height is biased quite high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7147d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    heights.groupby('gender')['child'].mean().rename('Original'),\n",
    "    heights_mar.groupby('gender')['child'].mean().rename('MAR, Unfilled'),\n",
    "    heights_mar_mfilled.groupby('gender')['child'].mean().rename('MAR, Mean Imputed')\n",
    "], axis=1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deca40b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Within-group (conditional) mean imputation\n",
    "\n",
    "* **Improvement:** Since MAR data are MCAR within each group, we can perform group-wise mean imputation.\n",
    "    - In our case, since the missingness of `'child'` is dependent on `'gender'`, we can impute separately for each `'gender'`.\n",
    "    - For instance, if there is a missing `'child'` height for a `'female'` child, impute their height with the mean observed `'female'` height.\n",
    "\n",
    "- With this technique, the overall mean remains unbiased, as do the within-group means.\n",
    "\n",
    "- Like with \"single\" mean imputation, the variance of the dataset is reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b02c4a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `transform` returns!\n",
    "\n",
    "- In MAR data, imputation by the overall mean gives a biased estimate of the mean of each group. \n",
    "- To obtain an unbiased estimate of the mean within each group, impute using the mean within each group.\n",
    "- To perform an operation separately to each gender, we `groupby('gender')` and use the `transform` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1281b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc11b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map['MAR, Conditional Mean Imputed'] = heights_mar_cond\n",
    "util.multiple_kdes(df_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8dbbba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The <span style='color:rgb(231,41,138)'><b>pink distribution</b></span> does a slightly better job of approximating the <span style='color:rgb(27,158,119)'><b>turquoise distribution</b></span> than the <span style='color:rgb(117,112,179)'><b>purple distribution</b></span>, but not by much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a894f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conclusion: Imputation with single values\n",
    "\n",
    "- Imputing missing data in a column with the mean of the column:\n",
    "    - faithfully reproduces the mean of the observed dataset,\n",
    "    - reduces the variance, and\n",
    "    - biases relationships between the column and other columns if the data are not MCAR.\n",
    "    \n",
    "- The same is true with other statistics (e.g. median and mode)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987dff83",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probabilistic imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5f5afd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Imputing missing values using distributions\n",
    "\n",
    "- So far, each missing value in a column has been filled in with a constant value.\n",
    "    - This creates \"spikes\" in the imputed distributions.\n",
    "\n",
    "- **Idea**: We can **probabilistically** impute missing data from a distribution.\n",
    "    - We can fill in missing data by drawing from the distribution of the **non-missing** data.\n",
    "    - There are 5 missing values? Pick 5 values from the data that aren't missing.\n",
    "     - How? Using `np.random.choice` or `.sample`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032be30d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Probabilistic imputation in the MCAR `heights` dataset\n",
    "\n",
    "Step 1: Determine the number of missing values in the column of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679c290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_null = ...\n",
    "num_null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dad41c7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Step 2: Sample that number of values from the observed values in the column of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34572685",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_values = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f361a002",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Step 3: Fill in the missing values with the sample from Step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851d61d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mcar_pfilled = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dafeb8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba3ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = {'Original': heights, \n",
    "          'MCAR, Unfilled': heights_mcar, \n",
    "          'MCAR, Probabilistically Imputed': heights_mcar_pfilled}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78829e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.multiple_describe(df_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9882b3a8",
   "metadata": {},
   "source": [
    "Variance is preserved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da39dc8",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.multiple_kdes(df_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608c003e",
   "metadata": {},
   "source": [
    "No spikes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf71df0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Observations\n",
    "\n",
    "- With this technique, the missing values were filled in with observed values in the dataset.\n",
    "\n",
    "- If a value was never observed in the dataset, it will never be used to fill in a missing value.\n",
    "    - For instance, if the observed heights were 68, 69, and 69.5 inches, we will never fill a missing value with 68.5 inches even though it's a perfectly reasonable height.\n",
    "\n",
    "- Solution? Create a histogram (with `np.histogram`) to bin the data, then sample from the histogram.\n",
    "    - See Lab 5, Question 6.\n",
    "\n",
    "- **Question**: How would we generalize this process for MAR data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd86e579",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Randomness\n",
    "\n",
    "- Unlike mean imputation, probabilistic imputation is **random** ‚Äì each time you run the cell in which imputation is performed, the results could be different.\n",
    "\n",
    "- If we're interested in estimating some population **parameter** given our (incomplete) sample, it's best not to rely on just a single random imputation.\n",
    "\n",
    "- **Multiple imputation**: Generate multiple imputed datasets and aggregate the results!\n",
    "    - Similar to bootstrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893a4ba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multiple imputation\n",
    "\n",
    "Steps:\n",
    "\n",
    "0. Start with observed and incomplete data. \n",
    "\n",
    "1. Create $m$ **imputed** versions of the data through a probabilistic procedure.\n",
    "    - The imputed datasets are identical for the observed data entries.\n",
    "    - They differ in the imputed values. \n",
    "    - The differences reflect our **uncertainty** about what value to impute.\n",
    "\n",
    "2. Then, compute parameter estimates on **each** imputed dataset.\n",
    "    - For instance, the mean, standard deviation, median, etc.\n",
    "\n",
    "3. Finally, pool the $m$ parameter estimates into one estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5230ef90",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multiple imputation\n",
    "\n",
    "Let's try this procedure out on the `heights_mcar` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59d0d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mcar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4516230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function implements the 3-step process we studied earlier.\n",
    "def create_imputed(col):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b6dfc3",
   "metadata": {},
   "source": [
    "Each time we run the following cell, it generates a new imputed version of the `'child'` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3150a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eff734",
   "metadata": {},
   "source": [
    "Let's run the above procedure 100 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6846822",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_imp = ...\n",
    "mult_imp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890eb62b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's plot some of the imputed columns on the previous slide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be635de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sample of 15 imputed columns.\n",
    "mult_imp_sample = mult_imp.sample(15, axis=1)\n",
    "fig = ff.create_distplot(mult_imp_sample.to_numpy().T, list(mult_imp_sample.columns), show_hist=False, show_rug=False)\n",
    "fig.update_xaxes(title='child')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d462c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at the distribution of means across the imputed columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f4afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(pd.DataFrame(mult_imp.mean()), nbins=15, histnorm='probability',\n",
    "             title='Distribution of Imputed Sample Means')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab3f396",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If the distrbution of imputed means is wide, this implies more uncertainty about what our missing values could have been ‚Äì useful!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269efd96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d8ef63",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary of imputation techniques\n",
    "\n",
    "* Listwise deletion.\n",
    "* Mean imputation.\n",
    "* Group-wise (conditional) mean imputation.\n",
    "* Probabilistic imputation.\n",
    "* Multiple imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a2875",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: Listwise deletion\n",
    "\n",
    "* Procedure: `df = df.dropna()`.\n",
    "* If data are MCAR, listwise deletion doesn't change most summary statistics (mean, median, SD) of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f440f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: Mean imputation \n",
    "\n",
    "* Procedure: `df[col] = df[col].fillna(df[col].mean())`.\n",
    "* If data are MCAR, the resulting mean is an unbiased estimate of the true mean, but the variance is too low.\n",
    "* Analogue for categorical data: imputation with the mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa5b192",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: Conditional mean imputation\n",
    "\n",
    "* Procedure: for a column `c1`, conditional on a second categorical column\n",
    "`c2`:\n",
    "\n",
    "```py\n",
    "means = df.groupby('c2').mean().to_dict()\n",
    "imputed = df['c1'].apply(lambda x: means[x] if np.isnan(x) else x)\n",
    "```\n",
    "\n",
    "* If data are MAR, the resulting mean is an unbiased estimate of the true mean, but the variance is too low.\n",
    "* This increases correlations between the columns.\n",
    "* If the column with missing values were dependent on *more than one* column, we can use linear regression to predict the missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338ffe56",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: Probabilistic imputation\n",
    "\n",
    "* Procedure: draw from the distribution of **observed data** to fill in missing values.\n",
    "* If data are MCAR, the resulting mean and variance are unbiased estimates of the true mean and variance.\n",
    "* Extending to the MAR case: draw from **conditional empirical distributions**.\n",
    "    - If data are conditional on a single categorical column `c2`, apply the MCAR procedure to the groups of `df.groupby(c2)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef74415",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: Multiple imputation\n",
    "\n",
    "* Procedure:\n",
    "    - Apply probabilistic imputation multiple times, resulting in $m$ imputed datasets.\n",
    "    - Compute statistics separately on the $m$ imputed datasets (e.g. compute the mean or correlation coefficient).\n",
    "    - Plot the distribution of these statistics and create confidence intervals.\n",
    "* If a column is missing conditional on multiple columns, your \"multiple imputations\" should include probabilistic imputations for each!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc2e7a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "- Introduction to HTTP.\n",
    "- Making requests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
